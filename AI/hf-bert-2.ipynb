{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colored-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/CodeGPT-small-py-adaptedGPT2\"\n",
    "model_name = \"microsoft/CodeGPT-small-py\"\n",
    "model_name=\"jaron-maene/gpt2-medium-nl2bash\"\n",
    "model_name=\"facebook/bart-large-mnli\"\n",
    "\n",
    "model_name = \"distilgpt2\"\n",
    "model_name = \"gpt2\"\n",
    "model_name = \"gpt2-large\"\n",
    "\n",
    "model_name=\"bert-base-uncased\"\n",
    "\n",
    "model_name=\"chrisliu298/arxiv_ai_gpt2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chubby-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed , EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chronic-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "simplified-india",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b90fd1fccec44959cfd2f91bf42ddd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f5987244ca423ab5da5107af721aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_fuser = EncoderDecoderModel.from_pretrained(\"google/roberta2roberta_L-24_discofuse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "speaking-creativity",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f0b0af5735f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"google/roberta2roberta_L-24_discofuse\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\conda\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers-4.2.2-py3.8.egg\\transformers\\models\\auto\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    391\u001b[0m                         \u001b[1;34m\"This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m                         \u001b[1;34m\"in order to use this tokenizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed in order to use this tokenizer."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/roberta2roberta_L-24_discofuse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-health",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-ridge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annoying-weapon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6503110077f142d7aa4720d11499e9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "PipelineException",
     "evalue": "The model 'BertLMHeadModel' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPipelineException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e87d1067b272>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text-generation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m142\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#>>> generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers-4.2.2-py3.8.egg\\transformers\\pipelines\\__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, framework, revision, use_fast, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelcard\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodelcard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\conda\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers-4.2.2-py3.8.egg\\transformers\\pipelines\\text_generation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_model_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALLOWED_MODELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# overriding _parse_and_tokenize to allow for unusual language-modeling tokenizer arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers-4.2.2-py3.8.egg\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36mcheck_model_type\u001b[1;34m(self, supported_models)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0msupported_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupported_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupported_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             raise PipelineException(\n\u001b[0m\u001b[0;32m    575\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPipelineException\u001b[0m: The model 'BertLMHeadModel' is not supported for text-generation. Supported models are ['XLNetLMHeadModel', 'TransfoXLLMHeadModel', 'ReformerModelWithLMHead', 'GPT2LMHeadModel', 'OpenAIGPTLMHeadModel', 'CTRLLMHeadModel', 'TFXLNetLMHeadModel', 'TFTransfoXLLMHeadModel', 'TFGPT2LMHeadModel', 'TFOpenAIGPTLMHeadModel', 'TFCTRLLMHeadModel']"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    ">>> generator = pipeline('text-generation', model=model_name)\n",
    ">>> set_seed(142)\n",
    "#>>> generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vanilla-track",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Anaconda is a Python distribution, and you need Python installed on your PC.\\n\\nYou will most definitely need to install the following packages.'},\n",
       " {'generated_text': 'Anaconda is a Python distribution, and not an actual OS. In a nutshell, it is an open source, cross platform development environment that aims'},\n",
       " {'generated_text': 'Anaconda is a Python distribution, with a nice development environment, great documentation and tons of useful command line tools. The documentation also has a tutorial'},\n",
       " {'generated_text': 'Anaconda is a Python distribution, and can be built in two different ways. Firstly, one may build from a CMD binary by following the'},\n",
       " {'generated_text': 'Anaconda is a Python distribution, so you can install it from PyPI.\\n\\nA second, more modern way of getting the python distribution'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Anaconda is a Python distribution,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "talented-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> set_seed(14243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-entertainment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \" Anaconda is a Python distribution, not a GUI. But, that's not a bad idea to adopt this philosophy. Here should be all the\"},\n",
       " {'generated_text': ' Anaconda is a Python distribution, with about 100 modules. It consists of modules that use the standard data structures of Django. It also provides a'},\n",
       " {'generated_text': ' Anaconda is a Python distribution, and this software does not require any installation. If you wish to run this command, the following instructions will work'},\n",
       " {'generated_text': ' Anaconda is a Python distribution, it uses Python 3.7.4.\\n\\nPyMiner:\\n\\nGems are a dependency'},\n",
       " {'generated_text': \" Anaconda is a Python distribution, which would explain why the project is so popular with some users, who might not know Python and haven't heard\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\" Anaconda is a Python distribution,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "better-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' Anaconda ... a Python distribution\\n\\n\\nJulie A. Bostwick, Ph.D.\\n\\nJohn C. Macon ... software'},\n",
       " {'generated_text': \" Anaconda ... a Python distribution\\n\\n\\nContributors\\n\\nThis project's contributors are:\\n\\nAndrew P. Davis (a Python web site\"},\n",
       " {'generated_text': ' Anaconda ... a Python distribution\\n\\n\\nPapa.cz ... principal architect\\n\\n\\nPaddy.cz ... visual and data security\\n\\n\\nRyan'},\n",
       " {'generated_text': ' Anaconda ... a Python distribution\\n\\n\\nhttps://github.com/shishida/pango\\n\\nhttps://github.com/sh'},\n",
       " {'generated_text': ' Anaconda ... a Python distribution\\n\\n\\nRafael Gonzalez, David A. Pannell, David I. Kuehlen, R'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\" Anaconda ... a Python distribution\\n\\n\\n\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "generous-former",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' Anaconda is a Python iced tea that tastes like a real tea. In this case, the main ingredient should be coconut milk; which is'},\n",
       " {'generated_text': ' Anaconda is a Python ive built toolkit for implementing the basic framework for Python programming language. From the beginning, Cython and Pygame'},\n",
       " {'generated_text': ' Anaconda is a Python \\xa0(or OCaml\\xa0 Python ) . But, I believe there is a different way you can use it'},\n",
       " {'generated_text': ' Anaconda is a Python xtra-node, a built-in node.\\n\\nA module called os that allows you to inspect the'},\n",
       " {'generated_text': ' Anaconda is a Python urs-platform application.\\n\\nInstallation\\n\\npython manage.py install\\n\\nIn order to create a Python'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\" Anaconda is a Python \", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "united-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \" Anaconda is a snake \\xa0for which we can find many\\xa0scientific studies\\xa0from time to time, but it's pretty clear that the\"},\n",
       " {'generated_text': ' Anaconda is a snake \\xa0(a snake \\xa0is a snake \\xa0is a snake \\xa0will \\xa0be found somewhere '},\n",
       " {'generated_text': \" Anaconda is a snake \\xa0that grows and dies on the forest floor along with the others, so you can't really blame them for losing\"},\n",
       " {'generated_text': ' Anaconda is a snake \\xa0that can be taken out by means of water, and sometimes by moving from its nest to its lair... but'},\n",
       " {'generated_text': ' Anaconda is a snake iba. It has a unique look and smell. She was the first to see that the snake had a venomous'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\" Anaconda is a snake \", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faced-equality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': ' Anaconda is a vernacular word for the tree of life. In English, it refers to grasses. See also the section on the'},\n",
       " {'generated_text': ' Anaconda is a vernacular noun for a group of people. They are known as \"The People\". These people may appear to be of'},\n",
       " {'generated_text': ' Anaconda is a iced coffee with fresh lime and mint infused to create the sweet and medicinal feel.\\n\\nLime infused to taste with'},\n",
       " {'generated_text': \" Anaconda is a vernacular term for an artificial or synthetic penis. It's a non-specific word that means a large penis with about\"},\n",
       " {'generated_text': ' Anaconda is a ichthyosis disease that appears when the lining of your blood vessels is thickened or damaged. It results from an attack'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\" Anaconda is a \", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-shark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-aside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-peoples",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
