{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n2QqmjC0esQ"
   },
   "source": [
    "# Word2Vec Application Tutorial\n",
    "In this tutorial, we go over basic operations on word vectors. There are many Natural Language Processing (NLP) libraries in Python, such as [NLTK](https://www.nltk.org/), [gensim](https://radimrehurek.com/gensim/), and [spaCy](https://spacy.io/). All of them have their own strength and focus. NLTK is one of the first comprehensive Python libraries for computational linguistics and has a big community. If you have worked on NLP, you probably have heard of it or used it. Gensim is a popular library for topic modeling. It also provides many functionalities similar to NLTK. It supports word embeddings and you can even train word embeddings using gensim. SpaCy is another popular NLP library and it provides built-in support for word vectors. We will use spaCy in this tutorial.  \\\\\n",
    "<br>\n",
    "You will learn:\n",
    "\n",
    "\n",
    "1.   Popular Python machine learning packages (spaCy, sklearn)\n",
    "2.   Calculating word similarity using Word2Vec model\n",
    "3.   Word analogy analysis\n",
    "4.   Calculating sentence similarity using Word2Vec model\n",
    "5.   Dimension reduction techniques for high-dimensional vectors\n",
    "6.   Visualizing Word2Vec in 2D space\n",
    "7.   Sentiment analysis using logistic regression and Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fymQg_Q068-"
   },
   "source": [
    "### Preliminary\n",
    "First, let's install the spaCy Python library and download their model for the English language. We only need to do it once. Then we can import the spaCy library and other useful libraries such as numpy (used for linear algebra and vector operations in Python). We can load our downloaded English model in our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VJCepyC9ZbX"
   },
   "outputs": [],
   "source": [
    "# Only needs to be run once at the top of the notebook\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# MNovy\n",
    "# in powershell prompt\n",
    "pip install sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jzPVan-OAIw8"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import spacy\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k9wiQz4BAuQT"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')  # load the English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNovy\n",
    "x=nlp.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x[406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auxpass'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.lower_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<spacy.lexeme.Lexeme at 0x18464695f80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695680>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695840>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695e40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646954c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695a00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695500>,\n",
       " <spacy.lexeme.Lexeme at 0x184646952c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695d80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695440>,\n",
       " <spacy.lexeme.Lexeme at 0x184646953c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695b40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695080>,\n",
       " <spacy.lexeme.Lexeme at 0x18464695300>,\n",
       " <spacy.lexeme.Lexeme at 0x184645aaf40>,\n",
       " <spacy.lexeme.Lexeme at 0x184645aaa00>,\n",
       " <spacy.lexeme.Lexeme at 0x184645aad80>,\n",
       " <spacy.lexeme.Lexeme at 0x184645aa540>,\n",
       " <spacy.lexeme.Lexeme at 0x18423777840>,\n",
       " <spacy.lexeme.Lexeme at 0x18423777040>,\n",
       " <spacy.lexeme.Lexeme at 0x18423777280>,\n",
       " <spacy.lexeme.Lexeme at 0x1840a076d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a67e40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a67140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a67fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a67240>,\n",
       " <spacy.lexeme.Lexeme at 0x184261d9940>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e700>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ea80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e540>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e400>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e340>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ea40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ed40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e3c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ec80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e880>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e380>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ef40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e640>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e2c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492eec0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492efc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e1c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492edc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ef80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e6c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e7c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e080>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e900>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ecc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e800>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ec40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e980>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e600>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ed00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ea00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e180>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e300>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e200>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e240>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ef00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e280>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e440>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e4c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492eac0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e040>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e140>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ee40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ee00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ed80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ec00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ebc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492eb80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492eb40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492e740>,\n",
       " <spacy.lexeme.Lexeme at 0x1846492ee80>,\n",
       " <spacy.lexeme.Lexeme at 0x1840a0a99c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464517900>,\n",
       " <spacy.lexeme.Lexeme at 0x18423a8f600>,\n",
       " <spacy.lexeme.Lexeme at 0x18423a8f5c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7f80>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7180>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7080>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7940>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7600>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7340>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7100>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7e80>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7e00>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7780>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7c40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7680>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7d40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a7ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbc7c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbc6c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbcf80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbcd40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbce80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbc380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbc640>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbc800>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bbce00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464068d80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464068e00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464068f80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464068d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464068f00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464068ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649acc40>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac200>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac580>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac4c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649acdc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac6c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ace80>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ace40>,\n",
       " <spacy.lexeme.Lexeme at 0x184649acd00>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac7c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac600>,\n",
       " <spacy.lexeme.Lexeme at 0x184649acd80>,\n",
       " <spacy.lexeme.Lexeme at 0x184649ac0c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184648548c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464854880>,\n",
       " <spacy.lexeme.Lexeme at 0x18464854840>,\n",
       " <spacy.lexeme.Lexeme at 0x18464854040>,\n",
       " <spacy.lexeme.Lexeme at 0x184648547c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464854980>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71780>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c714c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c718c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71280>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71400>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71940>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c713c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71d40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c712c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71800>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71bc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71880>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71480>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71340>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71e80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464c71980>,\n",
       " <spacy.lexeme.Lexeme at 0x184238a8cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184261fef80>,\n",
       " <spacy.lexeme.Lexeme at 0x18426201dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1840a0999c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746b40>,\n",
       " <spacy.lexeme.Lexeme at 0x184647463c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746f40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746580>,\n",
       " <spacy.lexeme.Lexeme at 0x184647466c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746240>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746940>,\n",
       " <spacy.lexeme.Lexeme at 0x184647460c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746900>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746d40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746840>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746e80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746a80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746f00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746080>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746800>,\n",
       " <spacy.lexeme.Lexeme at 0x184647465c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746280>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746b80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746f80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746880>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746e40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746040>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746480>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746c40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746600>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746d80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464746fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485600>,\n",
       " <spacy.lexeme.Lexeme at 0x184644855c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184644858c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485100>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485080>,\n",
       " <spacy.lexeme.Lexeme at 0x184644851c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464485900>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d780>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d140>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d980>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d340>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d800>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d700>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d680>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d740>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464db80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d500>,\n",
       " <spacy.lexeme.Lexeme at 0x1846464d540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3340>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3e00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb36c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3700>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb32c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3d80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3040>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3780>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb35c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3c80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3280>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3bc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb37c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3e40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3640>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb39c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3080>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3900>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3840>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb3980>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bb38c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754500>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754680>,\n",
       " <spacy.lexeme.Lexeme at 0x184647546c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754b80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464754a40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1980>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1a40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1d40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1900>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1f40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1500>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1f80>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1640>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1d00>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1d80>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1880>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f17c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1a00>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1840>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f12c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f11c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1280>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1040>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f13c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1f00>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f16c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1e80>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1680>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f19c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1740>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1540>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1c40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1b80>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1580>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1700>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1940>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1c00>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1e40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1140>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1e00>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1b40>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1080>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f10c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1600>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f1dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646f14c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18423aa9c80>,\n",
       " <spacy.lexeme.Lexeme at 0x18423aa9cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18423aa9dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18423aa9680>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771a00>,\n",
       " <spacy.lexeme.Lexeme at 0x184647710c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771b80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771480>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771040>,\n",
       " <spacy.lexeme.Lexeme at 0x184647712c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771e80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771c80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771a80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771880>,\n",
       " <spacy.lexeme.Lexeme at 0x184647716c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771080>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771e00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771d40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771800>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771640>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771780>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771700>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771600>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771400>,\n",
       " <spacy.lexeme.Lexeme at 0x184647715c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184647719c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184647711c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184647718c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771100>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771c40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771940>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771980>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771340>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771680>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771a40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771f40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771840>,\n",
       " <spacy.lexeme.Lexeme at 0x184647713c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771900>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771f80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771e40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771bc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184647717c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464771d80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528bc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184645281c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528f40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528a80>,\n",
       " <spacy.lexeme.Lexeme at 0x184645285c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184645288c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528a40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528f00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528740>,\n",
       " <spacy.lexeme.Lexeme at 0x184645282c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528b40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464528ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aaec0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aab40>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa0c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aad80>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aae80>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa1c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa640>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aac40>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aafc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa200>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa980>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa3c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa480>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aaf40>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa680>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa300>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa700>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa580>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aab00>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aaa00>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa2c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa840>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aad00>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa100>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa500>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa400>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa240>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa800>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa080>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa340>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aadc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aaf00>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aaa80>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa280>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aa940>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aae40>,\n",
       " <spacy.lexeme.Lexeme at 0x184649aabc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184237b7900>,\n",
       " <spacy.lexeme.Lexeme at 0x1846378ec00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846378ecc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460eb40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ec40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460eb80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ea00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ee40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e2c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ef80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e840>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ec80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e7c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e980>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ed00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e880>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460eb00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ee00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460e8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ef40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460ef00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846460edc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b380>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b5c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b6c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b280>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bec0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bf00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490be00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b900>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b600>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b540>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b500>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b480>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b3c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b240>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b0c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b440>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bfc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490be40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bdc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bd40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bd80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bbc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bc00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bac0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bb00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b740>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b780>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b080>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b040>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b680>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bcc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b640>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b940>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b840>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b7c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b700>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b580>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b400>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b180>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b140>,\n",
       " <spacy.lexeme.Lexeme at 0x184644e3b00>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a3ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3f80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af38c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3a80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3700>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3900>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3780>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3b80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af31c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af33c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3e00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3940>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464af3ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x184646ef340>,\n",
       " <spacy.lexeme.Lexeme at 0x184649d7940>,\n",
       " <spacy.lexeme.Lexeme at 0x184649d7bc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464d5b280>,\n",
       " <spacy.lexeme.Lexeme at 0x18464d5bf00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464665ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464665ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464665fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464665980>,\n",
       " <spacy.lexeme.Lexeme at 0x18464665d40>,\n",
       " <spacy.lexeme.Lexeme at 0x18461e4f040>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aacc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aac40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aa280>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aad00>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aa9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aa940>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aa580>,\n",
       " <spacy.lexeme.Lexeme at 0x184640aa380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b3f180>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b3f300>,\n",
       " <spacy.lexeme.Lexeme at 0x1846497c380>,\n",
       " <spacy.lexeme.Lexeme at 0x18464757640>,\n",
       " <spacy.lexeme.Lexeme at 0x18464757a40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a7f580>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a7fac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464a7f540>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3a80>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b30c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3d00>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3500>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3140>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b38c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3c40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3f80>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3980>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3740>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3580>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3a40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b32c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640b3300>,\n",
       " <spacy.lexeme.Lexeme at 0x18423a2e400>,\n",
       " <spacy.lexeme.Lexeme at 0x184644e1f00>,\n",
       " <spacy.lexeme.Lexeme at 0x184644e1ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x184644e1d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78900>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b780c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78e80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78a40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b786c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78b40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b782c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78c80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b788c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78600>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78a00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78880>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78980>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78a80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b783c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464b78500>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bcdb80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bcd700>,\n",
       " <spacy.lexeme.Lexeme at 0x18464bcd900>,\n",
       " <spacy.lexeme.Lexeme at 0x18423ac39c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894c80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894740>,\n",
       " <spacy.lexeme.Lexeme at 0x184648948c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184648945c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894bc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894640>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894700>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894600>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894d80>,\n",
       " <spacy.lexeme.Lexeme at 0x184648949c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894f00>,\n",
       " <spacy.lexeme.Lexeme at 0x184648942c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894980>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894680>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894780>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894f40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894380>,\n",
       " <spacy.lexeme.Lexeme at 0x184648947c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894040>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894e80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894a80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464894080>,\n",
       " <spacy.lexeme.Lexeme at 0x18464cffac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464857400>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499bd40>,\n",
       " <spacy.lexeme.Lexeme at 0x18463fe2340>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a84c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8840>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a88c0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8c40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8e00>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8c80>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8100>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8040>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8740>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8a00>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8900>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8700>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a8d40>,\n",
       " <spacy.lexeme.Lexeme at 0x184640a80c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464d3ac40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464d3a500>,\n",
       " <spacy.lexeme.Lexeme at 0x18464d3aec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464d3a340>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e1c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e540>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e500>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499efc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ef00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e300>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e100>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499eec0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ea00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e480>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e580>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ef40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499eb00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e400>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e3c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ee00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e180>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e800>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e440>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ed40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e2c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ee80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499eac0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e280>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e900>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e700>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e740>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ed00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ecc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ed80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ec80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e040>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499e980>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ef80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846499ea40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465eec0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ee40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ef40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e240>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e940>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e300>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e500>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e900>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e8c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ea80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e0c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465eb00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e9c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e7c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e100>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ec40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ed00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e840>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e340>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ecc0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e580>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e180>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e200>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e640>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e1c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465e6c0>,\n",
       " <spacy.lexeme.Lexeme at 0x1846465ed80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490b100>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bf40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490ba00>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490ba40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490ba80>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bb40>,\n",
       " <spacy.lexeme.Lexeme at 0x1846490bb80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954080>,\n",
       " <spacy.lexeme.Lexeme at 0x184649540c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954140>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954100>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954300>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954380>,\n",
       " <spacy.lexeme.Lexeme at 0x184649543c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954440>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954400>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954480>,\n",
       " <spacy.lexeme.Lexeme at 0x184649544c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954500>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954580>,\n",
       " <spacy.lexeme.Lexeme at 0x184649545c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954600>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954640>,\n",
       " <spacy.lexeme.Lexeme at 0x184649546c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954680>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954740>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954700>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954780>,\n",
       " <spacy.lexeme.Lexeme at 0x184649547c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954800>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954840>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954880>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954980>,\n",
       " <spacy.lexeme.Lexeme at 0x184649549c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954a80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954c00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954c40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954cc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954c80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954d00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954d40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954d80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954dc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954e00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954e40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954e80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954ec0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954f00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954f40>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954200>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954b00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954a00>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954f80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954ac0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954b80>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954fc0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954040>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954180>,\n",
       " <spacy.lexeme.Lexeme at 0x184649541c0>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954240>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954280>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954340>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954540>,\n",
       " <spacy.lexeme.Lexeme at 0x18464954900>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_lookups',\n",
       " '_reset_cache',\n",
       " 'add_flag',\n",
       " 'cfg',\n",
       " 'data_dir',\n",
       " 'from_bytes',\n",
       " 'from_disk',\n",
       " 'get_noun_chunks',\n",
       " 'get_vector',\n",
       " 'has_vector',\n",
       " 'lang',\n",
       " 'length',\n",
       " 'lex_attr_getters',\n",
       " 'lookups',\n",
       " 'morphology',\n",
       " 'prune_vectors',\n",
       " 'reset_vectors',\n",
       " 'set_vector',\n",
       " 'strings',\n",
       " 'to_bytes',\n",
       " 'to_disk',\n",
       " 'vectors',\n",
       " 'vectors_length',\n",
       " 'writing_system']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word='dgdfgdgf'\n",
    "allwordst = [w.text for w in nlp.vocab if w.has_vector and w.is_lower ] ## and w.lower_ != word.lower_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nuthin',\n",
       " 'p.m',\n",
       " 'c.',\n",
       " 'e.g',\n",
       " 'it',\n",
       " 'e',\n",
       " \"o'clock\",\n",
       " 'is',\n",
       " 'n.',\n",
       " 'where',\n",
       " 'g.',\n",
       " 'must',\n",
       " 'co.',\n",
       " 'had',\n",
       " 'vs.',\n",
       " 'x.',\n",
       " 'does',\n",
       " 'do',\n",
       " '’s',\n",
       " 'b',\n",
       " 'might',\n",
       " 'q.',\n",
       " 'pm',\n",
       " 'ought',\n",
       " 'h.',\n",
       " 'ä',\n",
       " 'these',\n",
       " 'somethin',\n",
       " 'z.',\n",
       " 'ü',\n",
       " 'r',\n",
       " 'v.s',\n",
       " 'o_o',\n",
       " \"'cause\",\n",
       " 'co',\n",
       " 'doin',\n",
       " 'i.e',\n",
       " 'i.e.',\n",
       " 'g',\n",
       " 'n’t',\n",
       " 'w',\n",
       " 'cos',\n",
       " 'would',\n",
       " 'a.',\n",
       " 'k',\n",
       " 'o.',\n",
       " 'd',\n",
       " 'f',\n",
       " 'need',\n",
       " 'c',\n",
       " 'v.s.',\n",
       " 'm',\n",
       " 'cause',\n",
       " 'm.',\n",
       " 'you',\n",
       " 'was',\n",
       " 'y',\n",
       " 'nt',\n",
       " 'who',\n",
       " \"'ve\",\n",
       " 'why',\n",
       " 'how',\n",
       " 'could',\n",
       " 'h',\n",
       " '0_o',\n",
       " \"'m\",\n",
       " 'ca',\n",
       " 'o’clock',\n",
       " ':p',\n",
       " 'cuz',\n",
       " 'o.o',\n",
       " 'a.m',\n",
       " 'those',\n",
       " 'space',\n",
       " \"n't\",\n",
       " 'were',\n",
       " 't',\n",
       " 'ta',\n",
       " 'a',\n",
       " 'dare',\n",
       " '’cause',\n",
       " '’re',\n",
       " 'll',\n",
       " 'this',\n",
       " 'j.',\n",
       " 'car',\n",
       " 'nuff',\n",
       " 'they',\n",
       " 'he',\n",
       " ':-p',\n",
       " 'l',\n",
       " 'u',\n",
       " 'q',\n",
       " 'there',\n",
       " 'havin',\n",
       " 'gon',\n",
       " 'b.',\n",
       " 'v',\n",
       " 'got',\n",
       " 'w/o',\n",
       " 'j',\n",
       " 'bout',\n",
       " \"that's\",\n",
       " 'v_v',\n",
       " 'k.',\n",
       " 'a.m.',\n",
       " 'or',\n",
       " 'when',\n",
       " 'o_0',\n",
       " \"it's\",\n",
       " 'she',\n",
       " 'may',\n",
       " 'all',\n",
       " 'v.v',\n",
       " 'what',\n",
       " 'p.m.',\n",
       " 'and/or',\n",
       " \"'s\",\n",
       " 'coz',\n",
       " 'i.',\n",
       " 'nothin',\n",
       " 'dog',\n",
       " 're',\n",
       " 'lovin',\n",
       " \"ma'am\",\n",
       " 'e.g.',\n",
       " 'not',\n",
       " 'did',\n",
       " 'w.',\n",
       " 'f.',\n",
       " 'e.',\n",
       " 'has',\n",
       " 'have',\n",
       " 'sha',\n",
       " 'd.',\n",
       " 'vs',\n",
       " 's',\n",
       " 'p.',\n",
       " 'p',\n",
       " \"'ll\",\n",
       " \"'re\",\n",
       " 'am',\n",
       " 'ol',\n",
       " 'cat',\n",
       " 'can',\n",
       " 'we',\n",
       " 'n',\n",
       " 'em',\n",
       " 'on',\n",
       " 'x',\n",
       " '’ve',\n",
       " 'that',\n",
       " 'o',\n",
       " 'y.',\n",
       " \"y'\",\n",
       " \"'d\",\n",
       " 'na',\n",
       " 'i',\n",
       " '’ll',\n",
       " 't.',\n",
       " \"'em\",\n",
       " 'v.',\n",
       " 'z',\n",
       " '’em',\n",
       " 'ö',\n",
       " 'ai',\n",
       " 'r.',\n",
       " 'l.',\n",
       " 's.',\n",
       " 'wo',\n",
       " 'u.',\n",
       " 'should',\n",
       " 'are',\n",
       " 'and',\n",
       " 'goin',\n",
       " 'let',\n",
       " 've']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allwordst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfpycYEG2T3y"
   },
   "source": [
    "### Word Similarity\n",
    "By representing words in vectors, we can use linear algebra and vector space models to analyze the relationship between words. One simple task is to calculate the cosine of two word vectors, namely the cosine similarity. This cosine similarity measures the semantic similarity of words. While the value ranges from -1 to 1, it is usually used in the non-negative space [0, 1] where 0 means 0 similarity and 1 means extremely similar or even identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm-5ZI0gHp-w"
   },
   "source": [
    "In order to calculate the cosine similarity between words, we have to know their vector representations first, which are provided by the Word2Vec model. In the spaCy English model, these vector representations (pretrained using Word2Vec) are already provided. All we need to do is to retrieve these words from the spaCy English model and we will have access to these vector representations. \\\\\n",
    "<br>\n",
    "![cosine_sim](https://engineering.aweber.com/wp-content/uploads/2013/02/4AUbj.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "id": "A-HL5bHMA3RE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector length: 300\n",
      "cat: [-0.15067   -0.024468  -0.23368   -0.23378   -0.18382    0.32711\n",
      " -0.22084   -0.28777    0.12759    1.1656    -0.64163   -0.098455\n",
      " -0.62397    0.010431  -0.25653    0.31799    0.037779   1.1904\n",
      " -0.17714   -0.2595    -0.31461    0.038825  -0.15713   -0.13484\n",
      "  0.36936   -0.30562   -0.40619   -0.38965    0.3686     0.013963\n",
      " -0.6895     0.004066  -0.1367     0.32564    0.24688   -0.14011\n",
      "  0.53889   -0.80441   -0.1777    -0.12922    0.16303    0.14917\n",
      " -0.068429  -0.33922    0.18495   -0.082544  -0.46892    0.39581\n",
      " -0.13742   -0.35132    0.22223   -0.144     -0.048287   0.3379\n",
      " -0.31916    0.20526    0.098624  -0.23877    0.045338   0.43941\n",
      "  0.030385  -0.013821  -0.093273  -0.18178    0.19438   -0.3782\n",
      "  0.70144    0.16236    0.0059111  0.024898  -0.13613   -0.11425\n",
      " -0.31598   -0.14209    0.028194   0.5419    -0.42413   -0.599\n",
      "  0.24976   -0.27003    0.14964    0.29287   -0.31281    0.16543\n",
      " -0.21045   -0.4408     1.2174     0.51236    0.56209    0.14131\n",
      "  0.092514   0.71396   -0.021051  -0.33704   -0.20275   -0.36181\n",
      "  0.22055   -0.25665    0.28425   -0.16968    0.058029   0.61182\n",
      "  0.31576   -0.079185   0.35538   -0.51236    0.4235    -0.30033\n",
      " -0.22376    0.15223   -0.048292   0.23532    0.46507   -0.67579\n",
      " -0.32905    0.08446   -0.22123   -0.045333   0.34463   -0.1455\n",
      " -0.18047   -0.17887    0.96879   -1.0028    -0.47343    0.28542\n",
      "  0.56382   -0.33211   -0.38275   -0.2749    -0.22955   -0.24265\n",
      " -0.37689    0.24822    0.36941    0.14651   -0.37864    0.31134\n",
      " -0.28449    0.36948   -2.8174    -0.38319   -0.022373   0.56376\n",
      "  0.40131   -0.42131   -0.11311   -0.17317    0.1411    -0.13194\n",
      "  0.18494    0.097692  -0.097341  -0.23987    0.16631   -0.28556\n",
      "  0.0038654  0.53292   -0.32367   -0.38744    0.27011   -0.34181\n",
      " -0.27702   -0.67279   -0.10771   -0.062189  -0.24783   -0.070884\n",
      " -0.20898    0.062404   0.022372   0.13408    0.1305    -0.19546\n",
      " -0.46849    0.77731   -0.043978   0.3827    -0.23376    1.0457\n",
      " -0.14371   -0.3565    -0.080713  -0.31047   -0.57822   -0.28067\n",
      " -0.069678   0.068929  -0.16227   -0.63934   -0.62149    0.11222\n",
      " -0.16969   -0.54637    0.49661    0.46565    0.088294  -0.48496\n",
      "  0.69263   -0.068977  -0.53709    0.20802   -0.42987   -0.11921\n",
      "  0.1174    -0.18443    0.43797   -0.1236     0.3607    -0.19608\n",
      " -0.35366    0.18808   -0.5061     0.14455   -0.024368  -0.10772\n",
      " -0.0115     0.58634   -0.054461   0.0076487 -0.056297   0.27193\n",
      "  0.23096   -0.29296   -0.24325    0.10317   -0.10014    0.7089\n",
      "  0.17402   -0.0037509 -0.46304    0.11806   -0.16457   -0.38609\n",
      "  0.14524    0.098122  -0.12352   -0.1047     0.39047   -0.3063\n",
      " -0.65375   -0.0044248 -0.033876   0.037114  -0.27472    0.0053147\n",
      "  0.30737    0.12528   -0.19527   -0.16461    0.087518  -0.051107\n",
      " -0.16323    0.521      0.10822   -0.060379  -0.71735   -0.064327\n",
      "  0.37043   -0.41054   -0.2728    -0.30217    0.015771  -0.43056\n",
      "  0.35647    0.17188   -0.54598   -0.21541   -0.044889  -0.10597\n",
      " -0.54391    0.53908    0.070938   0.097839   0.097908   0.17805\n",
      "  0.18995    0.49962   -0.18529    0.051234   0.019574   0.24805\n",
      "  0.3144    -0.29304    0.54235    0.46672    0.26017   -0.44705\n",
      "  0.28287   -0.033345  -0.33181   -0.10902   -0.023324   0.2106\n",
      " -0.29633    0.81506    0.038524   0.46004    0.17187   -0.29804  ]\n"
     ]
    }
   ],
   "source": [
    "# retrieve words from the English model vocabulary\n",
    "cat = nlp.vocab['cat']\n",
    "dog = nlp.vocab['dog']\n",
    "car = nlp.vocab['car']\n",
    "\n",
    "# print the dimension of word vectors\n",
    "print('vector length:', len(cat.vector))\n",
    "\n",
    "# print the word vector\n",
    "print('cat:', cat.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmpDwypeHSIy"
   },
   "source": [
    "Try to retrieve some other words and check if they have the same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NO5S4yX9hgZg",
    "outputId": "2d2bc1d0-cb11-494c-8545-8ada56a9146c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# try your own words and check if they have the same dimension of the cat vector\n",
    "############# YOUR CODE HERE ################\n",
    "computer = nlp.vocab['computer']\n",
    "\n",
    "print(len(computer.vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-g5mO0AfIT94"
   },
   "source": [
    "After retrieving the words and their vector representations, we can use the built-in similarity function (which implements cosine similarity) to calculate word similarity based on these vectors. Is 'cat' more similar to 'dog' than 'car'? Can you find some properties of cosine similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "lpxnslv1DB7e",
    "outputId": "6238a098-248b-47b5-95be-0e02fbd757fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between cat and cat: 1.0\n",
      "The similarity between cat and dog: 0.80168545\n",
      "The similarity between dog and cat: 0.80168545\n",
      "The similarity between cat and car: 0.31907532\n",
      "The similarity between dog and car: 0.3562916\n"
     ]
    }
   ],
   "source": [
    "# you can calculate the similarity between words using \n",
    "# the built-in 'similarity' function\n",
    "print('The similarity between cat and cat:', cat.similarity(cat))\n",
    "print('The similarity between cat and dog:', cat.similarity(dog))\n",
    "print('The similarity between dog and cat:', dog.similarity(cat))\n",
    "print('The similarity between cat and car:', cat.similarity(car))\n",
    "print('The similarity between dog and car:', dog.similarity(car))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pe1G8CvuIxIP"
   },
   "source": [
    "Now let's try some other words. Also, try to calculate the cosine similarity between 'hotel' and 'motel' and the cosine similarity between 'hotel' and 'hospital'. Which one is more similar to 'hotel'? 'motel' or 'hospital'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "QALZbd0Jhjlf",
    "outputId": "da78571a-a2c8-445e-c899-25c74f326d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74046886\n",
      "0.3863955\n"
     ]
    }
   ],
   "source": [
    "# calculate the similarity of your own words using the built-in function\n",
    "############# YOUR CODE HERE ################\n",
    "hotel = nlp.vocab['hotel']\n",
    "motel = nlp.vocab['motel']\n",
    "hospital = nlp.vocab['hospital']\n",
    "\n",
    "# what is the similarity between (hotel, motel) and (hotel, hospital)\n",
    "############# YOUR CODE HERE ################\n",
    "print(hotel.similarity(motel))\n",
    "\n",
    "print(hotel.similarity(hospital))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jwt8kG5Kuof"
   },
   "source": [
    "Let's compute the cosine similarity manually using its definition below. Then check if the result is the same as the one calculated by the built-in function. \\\\\n",
    "<br>\n",
    "$cosine\\_similarity(A, B) = \\frac{A \\cdot B}{\\left \\| A \\right \\|\\left \\| B \\right \\|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_3ZzlyeLhm3e",
    "outputId": "110941c4-e496-45b4-8b6b-10728d266088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between dog and car calculated manually: 0.3562916\n"
     ]
    }
   ],
   "source": [
    "# try to calculate cosine similarity manually\n",
    "'''\n",
    "cosine of V1 and V2 = dot product of V1 and V2 / product of V1 norm and V2 norm\n",
    "To get the vector representation of a word, use .vector, e.g. car.vector\n",
    "To calculate the dot product of two vectors V1 and V2, use np.dot(V1, V2)\n",
    "To get the norm of a word vector, use .vector_norm, e.g. car.vector_norm, \n",
    "alternatively you can use np.linalg.norm(V1) to calculate the norm of V1\n",
    "'''\n",
    "############# YOUR CODE HERE ################\n",
    "cosine_dog_car = np.dot(dog.vector, car.vector)/(dog.vector_norm*car.vector_norm)\n",
    "print('The similarity between dog and car calculated manually:', cosine_dog_car)\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ma4PgQeaMZfM"
   },
   "source": [
    "Now we know how to compare the similarity of two words using pretrained Word2Vec model. We can also use it to help us find semantically similar words, that is given a word retrieve similar words from the vocabulary. \\\\\n",
    "<br>\n",
    "The Python spaCy library hasn't provided such a function to do precisely this yet. We could use other NLP and machine learning libraries, such as [gensim](https://radimrehurek.com/gensim/), to do this with a simple function call. But the implementation is not hard, so let's give it a try! In our customized function, we first find all the words in our vocabulary (that has vector representations). Then we calculate the cosine similarity between our query word and each word in the vocabulary. We sort the similarity score in descending order. Finally, we retrieve the top n most similar words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "j6dRHeE6KBq5"
   },
   "outputs": [],
   "source": [
    "# function to find similar words\n",
    "def most_similar(word, topn=10):\n",
    "    allwords = [w for w in nlp.vocab if w.has_vector and w.is_lower and w.lower_ != word.lower_]  # get all words in the vocabulary\n",
    "    by_similarity = sorted(allwords, key=lambda w: word.similarity(w), reverse=True)  # sort words by similarity in descending order\n",
    "    return by_similarity[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "UCemJQbROBpi",
    "outputId": "90c7fdde-7399-483e-f5f3-67434fd791e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to cat:  ['dog', 'ca', 'she', 'i', 'when', 'does', 'got', \"n't\", 'cuz', 'u']\n"
     ]
    }
   ],
   "source": [
    "# find similar words\n",
    "cat_similar = [w.text for w in most_similar(cat)] #dog)]\n",
    "print('Similar words to cat: ', cat_similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYclgBII2gc7"
   },
   "source": [
    "### Word Analogy\n",
    "One interesting finding for the Word2Vec model is that it embeds some analogical relationships between words. \\\\\n",
    "<br>\n",
    "*Man is to Woman as King is to Queen* \\\\\n",
    "Man - Woman = King - Queen \\\\\n",
    "<br>\n",
    "*Paris is to France as Madrid is to Spain* \\\\\n",
    "Paris - France = Madrid - Spain \\\\\n",
    "<br>\n",
    "These relationships can be reconstructed using word embeddings. \\\\\n",
    "<br>\n",
    "![analogy](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/06062705/Word-Vectors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "v6Xo9Prcfpoy"
   },
   "outputs": [],
   "source": [
    "# word analogy example\n",
    "# king is to man as what is to woman?\n",
    "king = nlp.vocab['king']\n",
    "man = nlp.vocab['man']\n",
    "woman = nlp.vocab['woman']\n",
    "\n",
    "# resulting vector\n",
    "result = king.vector - man.vector + woman.vector\n",
    "\n",
    "# function to compute cosine similarity\n",
    "cosine = lambda v1, v2: np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word analogy example\n",
    "# king is to man as what is to woman?\n",
    "king = nlp.vocab['king']\n",
    "man = nlp.vocab['man']\n",
    "woman = nlp.vocab['woman']\n",
    "\n",
    "alfa1=1.3#0.0#0.1#0.2#0.3#0.4#0.5#0.6#0.7#0.8#0.9#1.0 #1.1 #1.2\n",
    "\n",
    "# resulting vector\n",
    "result = king.vector/king.vector_norm +alfa1*(- man.vector/man.vector_norm + woman.vector/woman.vector_norm)\n",
    "\n",
    "# function to compute cosine similarity\n",
    "cosine = lambda v1, v2: np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "vg_R5y2MyWFv",
    "outputId": "3cee2997-22d0-4590-d7df-6736b49fb872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between queen and result: 0.734625\n",
      "['queen', 'she', 'r.', 'who', 'dare']\n"
     ]
    }
   ],
   "source": [
    "# what word does the 'result' vector closely correspond to?\n",
    "\n",
    "# we can first check if the 'result' vector is similar to the 'queen' vector\n",
    "############# YOUR CODE HERE ################\n",
    "queen = nlp.vocab['queen']\n",
    "print('Similarity between queen and result:', cosine(result, queen.vector))\n",
    "#############################################\n",
    "\n",
    "# find all words in our vocabulary (nlp.vocab), \n",
    "# make sure to just retrieve lower case words \n",
    "# and words that actually have vectors (.has_vector) \n",
    "# and filter out 'king', 'man', and 'woman'\n",
    "############# YOUR CODE HERE ################\n",
    "allwords = [w for w in nlp.vocab if w.has_vector and w.is_lower and w.lower_ != 'king' and w.lower_ != 'man' and w.lower_ != 'woman']\n",
    "#############################################\n",
    "\n",
    "# calculate the cosine similarity between the 'result' vector \n",
    "# and all word vectors in our vocabulary\n",
    "# sort by similarity and print out the most similar one\n",
    "############# YOUR CODE HERE ################\n",
    "candidates = sorted(allwords, key=lambda w: cosine(result, w.vector), reverse=True)\n",
    "print([c.text for c in candidates[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1089217802006726"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.std()*math.sqrt(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0033581224"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25720182"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22875682"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.110446144175565"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(np.dot(result,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1104461"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8297405"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queen.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1417456"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.352939"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man.vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.8987513"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woman.vector_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHDhFaO2VaFJ"
   },
   "source": [
    "Let's try: \\\\\n",
    "Paris - France = Madrid - Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "unaXunKv0Y0F",
    "outputId": "1c968798-93b5-4178-af5c-c222f6846025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPAIN', 'spain', 'Spain', 'barcelona', 'Barcelona']\n"
     ]
    }
   ],
   "source": [
    "# another example\n",
    "# Paris is to France as Madrid is to what?\n",
    "############# YOUR CODE HERE ################\n",
    "Paris = nlp.vocab['Paris']\n",
    "France = nlp.vocab['France']\n",
    "Madrid = nlp.vocab['Madrid']\n",
    "\n",
    "maybe_Spain = France.vector - Paris.vector + Madrid.vector\n",
    "\n",
    "allwords = [w for w in nlp.vocab if w.has_vector and w.lower_ != 'paris' and w.lower_ != 'madrid' and w.lower_ != 'france']\n",
    "candidates = sorted(allwords, key=lambda w: cosine(maybe_Spain, w.vector), reverse=True)\n",
    "print([c.text for c in candidates[:5]])\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFPYDPuX6thm"
   },
   "source": [
    "### Sentence/Document Level Similarity\n",
    "Using word embeddings, we can also calculate similarity between sentences and documents. More advanced models such as Doc2Vec or neural networks can be used, but in this tutorial we will continue to use Word2Vec model to calculate document similarity. Since sentences and documents are composed of words, one easy way to obtain vector representations for sentences/documents is to calculate the average vectors of words. \\\\\n",
    "<br>\n",
    "Let's try to calculate the similarity among these three sentences:\n",
    "\n",
    "\n",
    "1.   Cats are beautiful animals.\n",
    "2.   Some gorgeous creatures are felines.\n",
    "3.   Dolphins are swimming mammals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "OiS9WQyG8zqG",
    "outputId": "cefb5493-e5aa-46bc-f75f-5a18d829ee09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9115828\n",
      "0.7822957\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec model does not provide vector representations for sentences \n",
    "# or documents. How is the similarity between sentences computed?\n",
    "# Since sentences are composed of words, an easy way to obtain the vector\n",
    "# representations of sentences is by averaging the vectors of each word in\n",
    "# the sentence.\n",
    "############# YOUR CODE HERE ################\n",
    "s1 = (nlp.vocab['Cats'].vector + nlp.vocab['are'].vector + nlp.vocab['beautiful'].vector + \\\n",
    "    nlp.vocab['animals'].vector + nlp.vocab['.'].vector)/5\n",
    "s2 = (nlp.vocab['Some'].vector + nlp.vocab['gorgeous'].vector + nlp.vocab['creatures'].vector + \\\n",
    "    nlp.vocab['are'].vector + nlp.vocab['felines'].vector + nlp.vocab['.'].vector)/6\n",
    "s3 = (nlp.vocab['Dolphins'].vector + nlp.vocab['are'].vector + nlp.vocab['swimming'].vector + \\\n",
    "    nlp.vocab['mammals'].vector + nlp.vocab['.'].vector)/5\n",
    "\n",
    "print(cosine(s1, s2))\n",
    "\n",
    "print(cosine(s1, s3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "w_P6Ep9F67Lu",
    "outputId": "45c96880-c6b4-442b-a78d-7e510583c74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between target and doc1: 0.9115828449161616\n",
      "Similarity between target and doc1: 0.7822956256736615\n"
     ]
    }
   ],
   "source": [
    "# spaCy also supports similarity calculation between sentences and documents\n",
    "target = nlp(\"Cats are beautiful animals.\")  # text about cats\n",
    "\n",
    "doc1 = nlp(\"Some gorgeous creatures are felines.\")  # text about cats\n",
    "doc2 = nlp(\"Dolphins are swimming mammals.\")  # text about dolphins\n",
    "\n",
    "print('Similarity between target and doc1:', target.similarity(doc1))\n",
    "print('Similarity between target and doc1:', target.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYs9_tHSFBhd"
   },
   "source": [
    "### Word Embeddings Visualization\n",
    "Since the word vectors we use have 300 dimensions, we cannot visualize them. One natural way is to apply dimension reduction first and then visualize them. We use a popular dimension reduction technique called [t-SNE](https://lvdmaaten.github.io/tsne/) (you can also use PCA) to reduce the word vectors to 2D and then plot the words in our word analogy example to see if we can find some pattern visually. \\\\\n",
    "<br>\n",
    "An interactive visualization of word embeddings can be found here: \\\\\n",
    "[https://projector.tensorflow.org/](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "HUnAim1BFH50",
    "outputId": "40f03508-b4be-4c90-d0d9-cd0928cdfd38"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD5CAYAAADSiMnIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41fcaf7400>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use t-SNE to do dimension reduction, from 300d to 2d\n",
    "tsne_model = TSNE(n_components=2)\n",
    "\n",
    "# get transformed vectors\n",
    "data = np.array([king.vector, man.vector, queen.vector, woman.vector])\n",
    "data_2d = tsne_model.fit_transform(data)\n",
    "\n",
    "labels = ['king', 'man', 'queen', 'woman']\n",
    "\n",
    "# plot the 2d vectors and show their labels\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1], s=100)\n",
    "for i, txt in enumerate(labels):\n",
    "    plt.annotate(txt, (data_2d[i,0], data_2d[i,1]), xytext=(2, 3), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXzQ0M-OW0h0"
   },
   "source": [
    "### Sentiment Analysis\n",
    "The major reason for coming up with word embedding models is that we want to use these embeddings which encode the word semantics to help us tackle problems related with natural language. \\\\\n",
    "<br>\n",
    "One such task is sentiment analysis. By analyzing the sentiment of texts, we want to understand whether a given sentence/document is positive or negative. For example, 'the weather is so nice today' has a positive sentiment whereas 'he is bored by the movie' has a negative sentiment. \\\\\n",
    "<br>\n",
    "In this tutorial, we want to use the word embeddings combined with a simple machine learning model ([logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) to do sentiment analysis. Logistic regression is a linear classification model and in our case we want to classify whether a given sentence is positive or negative. So it's a binary classification. \\\\\n",
    "<br>\n",
    "![logistic](https://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression_files/logistic_regression_schematic.png)\n",
    "<br>\n",
    "Our training data contains 2,748 from Yelp reviews, IMDB movie reviews, and Amazon reviews. In the dataset, 1 means positive and 0 means negative. The original data can be downloaded from [here](https://www.kaggle.com/rahulin05/sentiment-labelled-sentences-data-set/data), the combined file can be downloaded from [here](https://drive.google.com/file/d/1knrjvDNkiXtviXBoLm5OJY45_kcCmDxe/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "8LliIw9nW4Fc",
    "outputId": "d701cabd-4393-41a3-caea-5800e4610f2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-95525da2-7fd0-4282-b7cd-a91072602343\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-95525da2-7fd0-4282-b7cd-a91072602343\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving combined_training.txt to combined_training.txt\n"
     ]
    }
   ],
   "source": [
    "# load files into the environment\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "qGWb5845wEZZ",
    "outputId": "33b93cbb-56e2-45ed-8894-ba1d1f96b068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748\n",
      "[\"Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.\", 0]\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data_raw = []\n",
    "with open('combined_training.txt', newline='') as fr:\n",
    "    reader = csv.reader(fr, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        data_raw.append([row[0], int(row[1])])\n",
    "\n",
    "# print the number of data\n",
    "print(len(data_raw))\n",
    "\n",
    "# print the last data item\n",
    "print(data_raw[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "8U9GGTwFzTnE",
    "outputId": "d791076c-6009-48dc-9e8a-1048ea910d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2748, 300)\n",
      "(2748,)\n",
      "Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check. 0\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([nlp(d[0]).vector for d in data_raw])\n",
    "y_train = np.array([d[1] for d in data_raw])\n",
    "\n",
    "# print the dimension of x\n",
    "print(x_train.shape)\n",
    "\n",
    "# print the dimension of y\n",
    "print(y_train.shape)\n",
    "\n",
    "# double check\n",
    "print(nlp(data_raw[-1][0]).text, y_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "VwSJnk0A15LB",
    "outputId": "73076eeb-078c-422b-e9d2-f756c680bee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OTXDcQRq2JHF",
    "outputId": "89bae934-4ff1-4cae-f2a2-c0fe349516ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# predict using trained model\n",
    "predict = logreg.predict(np.array([nlp('the weather today is pleasant').vector, nlp('the food in this restaurant is beyond my expectation').vector]))\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "w2v.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
