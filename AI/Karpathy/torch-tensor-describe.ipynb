{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b422c0-c284-4a96-b59c-1f76cd097782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "081c64fd-2ea5-4bde-9057-0969119f4bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.2f'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "torch.set_printoptions(profile='short')\n",
    "%precision 2\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88099972-8c26-42c8-a78f-75e8df91b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=0)\n",
    "torch.set_printoptions(threshold=5)\n",
    "torch.set_printoptions(edgeitems=1)\n",
    "###torch.set_printoptions(edgeitems=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a83e3917-6e6c-4236-8e66-57a03d635a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1,  ...,  0],\n",
      "         ...,\n",
      "         [-1,  ...,  1]],\n",
      "\n",
      "        [[ 1,  ...,  1],\n",
      "         ...,\n",
      "         [ 0,  ..., -1]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.48"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(2,3, 4)\n",
    "print(x)\n",
    "\n",
    "\n",
    "# pytorch Compute the maximum absolute value of x\n",
    "def max_abs(x):\n",
    "    return torch.max(torch.abs(x.detach().cpu().flatten()  )) .item()\n",
    "    #np.abs(x.detach().numpy().flatten()).max()\n",
    "    \n",
    "max_abs(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87d123-faff-4f1f-aa0d-c6857adc89f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba1a76-639a-4f97-b247-cbe7f0c72552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9404b1-86ee-421e-b422-5cfc91b0b6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af3d9f-aec6-481a-abf4-a6e92cd47234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/fxmarty/tiny-testing-gpt2-remote-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bdae460-213f-40bc-b911-f6840bad91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\pip310\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead   #,  TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\")\n",
    "\n",
    "####model = TFAutoModel.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  \n",
    "model = AutoModelWithLMHead.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e40dc-014a-469a-8de5-8fb30b926c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/sshleifer/tiny-gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd8a3f89-4fd8-47c2-885a-76b449e2ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM  #, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained(\"sshleifer/tiny-gpt2\"  ) # ,  from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c309f07-c6ea-47cb-9e4c-642c5055227f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3109400545.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://huggingface.co/openai/gpt2\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://huggingface.co/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1da069c-1c2e-4257-a3b6-100d6b83395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef29d84-b073-4e94-bc2a-dc0a21d9b12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15299f0a-410b-42c1-85f2-f5ef196704fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             ('transformer.h.0.attn.masked_bias', tensor(-10000.)),\n",
    "             ('transformer.h.1.attn.masked_bias', tensor(-10000.)),\n",
    "             ('transformer.h.4.attn.masked_bias', tensor(-10000.)),\n",
    "        \n",
    "        .attn.masked_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "115a678b-114f-4d58-8330-44b2f1dc0127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.bias\n",
      "transformer.h.0.attn.masked_bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.bias\n",
      "transformer.h.1.attn.masked_bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.bias\n",
      "transformer.h.2.attn.masked_bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.bias\n",
      "transformer.h.3.attn.masked_bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.bias\n",
      "transformer.h.4.attn.masked_bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "my_dict=model.state_dict()\n",
    "for key in my_dict:\n",
    "    print(key  ) #, my_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9caf59c0-6dd6-45e0-bc40-be5a804eba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict=model.state_dict()\n",
    "set1=set(\n",
    "key for key in my_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e84093a-ace3-49d2-8df7-32788b63e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.h.0.attn.c_attn.bias',\n",
       " 'transformer.h.0.attn.c_attn.weight',\n",
       " 'transformer.h.0.attn.c_proj.bias',\n",
       " 'transformer.h.0.attn.c_proj.weight',\n",
       " 'transformer.h.0.ln_1.bias',\n",
       " 'transformer.h.0.ln_1.weight',\n",
       " 'transformer.h.0.ln_2.bias',\n",
       " 'transformer.h.0.ln_2.weight',\n",
       " 'transformer.h.0.mlp.c_fc.bias',\n",
       " 'transformer.h.0.mlp.c_fc.weight',\n",
       " 'transformer.h.0.mlp.c_proj.bias',\n",
       " 'transformer.h.0.mlp.c_proj.weight',\n",
       " 'transformer.h.1.attn.c_attn.bias',\n",
       " 'transformer.h.1.attn.c_attn.weight',\n",
       " 'transformer.h.1.attn.c_proj.bias',\n",
       " 'transformer.h.1.attn.c_proj.weight',\n",
       " 'transformer.h.1.ln_1.bias',\n",
       " 'transformer.h.1.ln_1.weight',\n",
       " 'transformer.h.1.ln_2.bias',\n",
       " 'transformer.h.1.ln_2.weight',\n",
       " 'transformer.h.1.mlp.c_fc.bias',\n",
       " 'transformer.h.1.mlp.c_fc.weight',\n",
       " 'transformer.h.1.mlp.c_proj.bias',\n",
       " 'transformer.h.1.mlp.c_proj.weight',\n",
       " 'transformer.h.2.attn.c_attn.bias',\n",
       " 'transformer.h.2.attn.c_attn.weight',\n",
       " 'transformer.h.2.attn.c_proj.bias',\n",
       " 'transformer.h.2.attn.c_proj.weight',\n",
       " 'transformer.h.2.ln_1.bias',\n",
       " 'transformer.h.2.ln_1.weight',\n",
       " 'transformer.h.2.ln_2.bias',\n",
       " 'transformer.h.2.ln_2.weight',\n",
       " 'transformer.h.2.mlp.c_fc.bias',\n",
       " 'transformer.h.2.mlp.c_fc.weight',\n",
       " 'transformer.h.2.mlp.c_proj.bias',\n",
       " 'transformer.h.2.mlp.c_proj.weight',\n",
       " 'transformer.h.3.attn.c_attn.bias',\n",
       " 'transformer.h.3.attn.c_attn.weight',\n",
       " 'transformer.h.3.attn.c_proj.bias',\n",
       " 'transformer.h.3.attn.c_proj.weight',\n",
       " 'transformer.h.3.ln_1.bias',\n",
       " 'transformer.h.3.ln_1.weight',\n",
       " 'transformer.h.3.ln_2.bias',\n",
       " 'transformer.h.3.ln_2.weight',\n",
       " 'transformer.h.3.mlp.c_fc.bias',\n",
       " 'transformer.h.3.mlp.c_fc.weight',\n",
       " 'transformer.h.3.mlp.c_proj.bias',\n",
       " 'transformer.h.3.mlp.c_proj.weight',\n",
       " 'transformer.h.4.attn.c_attn.bias',\n",
       " 'transformer.h.4.attn.c_attn.weight',\n",
       " 'transformer.h.4.attn.c_proj.bias',\n",
       " 'transformer.h.4.attn.c_proj.weight',\n",
       " 'transformer.h.4.ln_1.bias',\n",
       " 'transformer.h.4.ln_1.weight',\n",
       " 'transformer.h.4.ln_2.bias',\n",
       " 'transformer.h.4.ln_2.weight',\n",
       " 'transformer.h.4.mlp.c_fc.bias',\n",
       " 'transformer.h.4.mlp.c_fc.weight',\n",
       " 'transformer.h.4.mlp.c_proj.bias',\n",
       " 'transformer.h.4.mlp.c_proj.weight',\n",
       " 'transformer.ln_f.bias',\n",
       " 'transformer.ln_f.weight',\n",
       " 'transformer.wpe.weight',\n",
       " 'transformer.wte.weight'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict=model.state_dict()\n",
    "#set2=\n",
    "set(\n",
    "name for name, param in model.named_parameters()\n",
    ")\n",
    " #for name, param in \n",
    "    #    print(name )  #,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "793ee0d0-74c6-4be7-b4fd-4603071094fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lm_head.weight',\n",
       " 'transformer.h.0.attn.bias',\n",
       " 'transformer.h.0.attn.masked_bias',\n",
       " 'transformer.h.1.attn.bias',\n",
       " 'transformer.h.1.attn.masked_bias',\n",
       " 'transformer.h.2.attn.bias',\n",
       " 'transformer.h.2.attn.masked_bias',\n",
       " 'transformer.h.3.attn.bias',\n",
       " 'transformer.h.3.attn.masked_bias',\n",
       " 'transformer.h.4.attn.bias',\n",
       " 'transformer.h.4.attn.masked_bias'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1-set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a24a5e-e66f-40b3-a74a-f339ca246e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49fc2e45-0b25-4e1f-8e96-592e57aff902",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3406368243.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[57], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(name )  #,param)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "112c2a02-5e7e-422c-a0a7-eed7c58c44a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n"
     ]
    }
   ],
   "source": [
    " for name, param in model.named_parameters():\n",
    "        print(name )  #,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae4d62-edf4-4d67-adbd-2857b58fe547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39029cd-3407-4645-bce5-e4a1eb8ce4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d46086-fae1-4b37-96da-4350c7528b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef19b0d-63ee-413d-b4e6-f6f5ade95763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ce324-9b9d-4e1b-8d25-77cb3759c5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c208c-5563-48d7-86a7-c46c5d71e891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6058cc-0ec1-4a2c-a55e-3657f2adc538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51efe6c2-6fea-40d7-a3aa-9015bf89536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1.54646456)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
