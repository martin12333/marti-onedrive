{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b422c0-c284-4a96-b59c-1f76cd097782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by mm\n",
    "from mmilanutil import *\n",
    "#from mmilanutil import mmptmaxabs\n",
    "#import mmilanutil \n",
    "# restart kernel\n",
    "\n",
    "# pytorch Compute the maximum absolute value of x\n",
    "#def mmptmaxabs(x):\n",
    "    #return torch.max(torch.abs(x.detach().cpu().flatten()  )) .item()\n",
    "    ##np.abs(x.detach().numpy().flatten()).max()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7471f5e-2a47-47b3-b34e-e0a476b4b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marti\\OneDrive\\AI\\Karpathy\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4190e184-39cd-452c-8a48-c82534085eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmilanutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmmilanutil\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mmilanutil' is not defined"
     ]
    }
   ],
   "source": [
    "mmilanutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70556818-03cd-43be-8c04-c3baa5ee8df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function mmilanutil.mmptmaxabs(x)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmptmaxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031caef6-a1c8-4d59-8c61-0263e2d3a9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmilanutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmmilanutil\u001b[49m\u001b[38;5;241m.\u001b[39mmmptmaxabs\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mmilanutil' is not defined"
     ]
    }
   ],
   "source": [
    "mmilanutil.mmptmaxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6decb-d3c9-4ec9-b719-08151b5cd9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081c64fd-2ea5-4bde-9057-0969119f4bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.2f'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "torch.set_printoptions(profile='short')\n",
    "%precision 2\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a83e3917-6e6c-4236-8e66-57a03d635a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-8.30e-01, -9.11e-05, -5.41e-01, -1.14e+00],\n",
      "         [ 8.41e-02,  2.06e+00, -1.17e+00, -1.28e+00],\n",
      "         [-9.16e-02, -9.74e-01,  1.52e+00, -3.63e-01]],\n",
      "\n",
      "        [[ 6.13e-01, -2.62e-01, -8.05e-01,  5.15e-01],\n",
      "         [-1.26e+00,  1.79e+00, -1.30e-01, -1.39e+00],\n",
      "         [ 7.40e-01, -8.99e-01,  9.62e-01,  3.75e-01]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(2,3, 4)\n",
    "print(x)\n",
    "\n",
    "\n",
    "mmptmaxabs(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88099972-8c26-42c8-a78f-75e8df91b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=0)\n",
    "torch.set_printoptions(threshold=5)\n",
    "torch.set_printoptions(edgeitems=1)\n",
    "###torch.set_printoptions(edgeitems=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87d123-faff-4f1f-aa0d-c6857adc89f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba1a76-639a-4f97-b247-cbe7f0c72552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9404b1-86ee-421e-b422-5cfc91b0b6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af3d9f-aec6-481a-abf4-a6e92cd47234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/fxmarty/tiny-testing-gpt2-remote-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5bdae460-213f-40bc-b911-f6840bad91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\pip310\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead   #,  TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\")\n",
    "\n",
    "####model = TFAutoModel.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  \n",
    "model = AutoModelWithLMHead.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f4e40dc-014a-469a-8de5-8fb30b926c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/sshleifer/tiny-gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd8a3f89-4fd8-47c2-885a-76b449e2ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM  #, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained(\"sshleifer/tiny-gpt2\"  ) # ,  from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c309f07-c6ea-47cb-9e4c-642c5055227f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3109400545.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://huggingface.co/openai/gpt2\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://huggingface.co/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1da069c-1c2e-4257-a3b6-100d6b83395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef29d84-b073-4e94-bc2a-dc0a21d9b12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "02617297-289b-417e-94b6-badf810678f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.42"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict=model.state_dict()\n",
    "\n",
    "max(\n",
    "#param.shape for name, param in model.named_parameters()\n",
    "    mmptmaxabs(my_dict[key])  for key in my_dict if not key.endswith('.attn.bias') and not key.endswith('.attn.masked_bias')\n",
    ")\n",
    " #for name, param in \n",
    "    #    print(name )  #,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "058908c8-5ac5-412f-b435-f4f5a3f7e2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.42"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(\n",
    "#param.shape for name, param in model.named_parameters()\n",
    "    mmptmaxabs(param)  for name, param in model.named_parameters()\n",
    ")\n",
    " #for name, param in \n",
    "    #    print(name )  #,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876d578f-b7a2-4a1d-8d04-42e015f0ee2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d87c3-3372-4b77-b127-9cdd866aebe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975fc62-e90b-484a-b8c8-c084d254a90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8f419-3641-4b08-9998-dd3ef1c2b0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "61688a1d-461b-404a-af10-33e0b754daca",
   "metadata": {},
   "source": [
    "model.state_dict()\n",
    "\n",
    "#             ('transformer.h.0.attn.masked_bias', tensor(-10000.)),\n",
    "             ('transformer.h.1.attn.masked_bias', tensor(-10000.)),\n",
    "             ('transformer.h.4.attn.masked_bias', tensor(-10000.)),\n",
    "        \n",
    "        .attn.masked_bias\n",
    "'transformer.h.0.attn.bias',\n",
    "              tensor([[[[ True,  ..., False],\n",
    "                        ...,\n",
    "                        [ True,  ...,  True]]]])),\n",
    "                        \n",
    " lm_head.weight\n",
    "                       \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2f5afe7-8181-4e6b-b3c2-73db36f81e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.79"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmptmaxabs(model.state_dict()['lm_head.weight']  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04628b25-df30-497a-88fa-62febaa46ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b236d6c-c383-48d9-b82c-76a82f0c8af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "115a678b-114f-4d58-8330-44b2f1dc0127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.bias\n",
      "transformer.h.0.attn.masked_bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.bias\n",
      "transformer.h.1.attn.masked_bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.bias\n",
      "transformer.h.2.attn.masked_bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.bias\n",
      "transformer.h.3.attn.masked_bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.bias\n",
      "transformer.h.4.attn.masked_bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.bias\n",
      "transformer.h.5.attn.masked_bias\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.bias\n",
      "transformer.h.6.attn.masked_bias\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.bias\n",
      "transformer.h.7.attn.masked_bias\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.bias\n",
      "transformer.h.8.attn.masked_bias\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.bias\n",
      "transformer.h.9.attn.masked_bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.bias\n",
      "transformer.h.10.attn.masked_bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.bias\n",
      "transformer.h.11.attn.masked_bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "lm_head.weight\n"
     ]
    }
   ],
   "source": [
    "my_dict=model.state_dict()\n",
    "for key in my_dict:\n",
    "    print(key  ) #, my_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9caf59c0-6dd6-45e0-bc40-be5a804eba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict=model.state_dict()\n",
    "set1=set(\n",
    "key for key in my_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e84093a-ace3-49d2-8df7-32788b63e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict=model.state_dict()\n",
    "set2=set(\n",
    "name for name, param in model.named_parameters()\n",
    ")\n",
    " #for name, param in \n",
    "    #    print(name )  #,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "793ee0d0-74c6-4be7-b4fd-4603071094fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lm_head.weight',\n",
       " 'transformer.h.0.attn.bias',\n",
       " 'transformer.h.0.attn.masked_bias',\n",
       " 'transformer.h.1.attn.bias',\n",
       " 'transformer.h.1.attn.masked_bias',\n",
       " 'transformer.h.10.attn.bias',\n",
       " 'transformer.h.10.attn.masked_bias',\n",
       " 'transformer.h.11.attn.bias',\n",
       " 'transformer.h.11.attn.masked_bias',\n",
       " 'transformer.h.2.attn.bias',\n",
       " 'transformer.h.2.attn.masked_bias',\n",
       " 'transformer.h.3.attn.bias',\n",
       " 'transformer.h.3.attn.masked_bias',\n",
       " 'transformer.h.4.attn.bias',\n",
       " 'transformer.h.4.attn.masked_bias',\n",
       " 'transformer.h.5.attn.bias',\n",
       " 'transformer.h.5.attn.masked_bias',\n",
       " 'transformer.h.6.attn.bias',\n",
       " 'transformer.h.6.attn.masked_bias',\n",
       " 'transformer.h.7.attn.bias',\n",
       " 'transformer.h.7.attn.masked_bias',\n",
       " 'transformer.h.8.attn.bias',\n",
       " 'transformer.h.8.attn.masked_bias',\n",
       " 'transformer.h.9.attn.bias',\n",
       " 'transformer.h.9.attn.masked_bias'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1-set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a24a5e-e66f-40b3-a74a-f339ca246e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49fc2e45-0b25-4e1f-8e96-592e57aff902",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3406368243.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[57], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(name )  #,param)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "112c2a02-5e7e-422c-a0a7-eed7c58c44a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n"
     ]
    }
   ],
   "source": [
    " for name, param in model.named_parameters():\n",
    "        print(name )  #,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae4d62-edf4-4d67-adbd-2857b58fe547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39029cd-3407-4645-bce5-e4a1eb8ce4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d46086-fae1-4b37-96da-4350c7528b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef19b0d-63ee-413d-b4e6-f6f5ade95763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ce324-9b9d-4e1b-8d25-77cb3759c5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c208c-5563-48d7-86a7-c46c5d71e891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6058cc-0ec1-4a2c-a55e-3657f2adc538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51efe6c2-6fea-40d7-a3aa-9015bf89536e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.55"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##print\n",
    "(1.54646456)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efde49-f0aa-4712-94f8-3685ef7d9f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
