{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b422c0-c284-4a96-b59c-1f76cd097782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "081c64fd-2ea5-4bde-9057-0969119f4bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.2f'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "torch.set_printoptions(profile='short')\n",
    "%precision 2\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_printoptions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88099972-8c26-42c8-a78f-75e8df91b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=0)\n",
    "torch.set_printoptions(threshold=5)\n",
    "torch.set_printoptions(edgeitems=1)\n",
    "###torch.set_printoptions(edgeitems=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a83e3917-6e6c-4236-8e66-57a03d635a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1,  ...,  0],\n",
      "         ...,\n",
      "         [-1,  ...,  1]],\n",
      "\n",
      "        [[ 1,  ...,  1],\n",
      "         ...,\n",
      "         [ 0,  ..., -1]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.48"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(2,3, 4)\n",
    "print(x)\n",
    "\n",
    "\n",
    "# pytorch Compute the maximum absolute value of x\n",
    "def max_abs(x):\n",
    "    return torch.max(torch.abs(x.detach().cpu().flatten()  )) .item()\n",
    "    #np.abs(x.detach().numpy().flatten()).max()\n",
    "    \n",
    "max_abs(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87d123-faff-4f1f-aa0d-c6857adc89f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba1a76-639a-4f97-b247-cbe7f0c72552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9404b1-86ee-421e-b422-5cfc91b0b6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af3d9f-aec6-481a-abf4-a6e92cd47234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/fxmarty/tiny-testing-gpt2-remote-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bdae460-213f-40bc-b911-f6840bad91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\pip310\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead   #,  TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\")\n",
    "\n",
    "####model = TFAutoModel.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  \n",
    "model = AutoModelWithLMHead.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e40dc-014a-469a-8de5-8fb30b926c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/sshleifer/tiny-gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd8a3f89-4fd8-47c2-885a-76b449e2ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM  #, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained(\"sshleifer/tiny-gpt2\"  ) # ,  from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c309f07-c6ea-47cb-9e4c-642c5055227f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3109400545.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://huggingface.co/openai/gpt2\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://huggingface.co/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1da069c-1c2e-4257-a3b6-100d6b83395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef29d84-b073-4e94-bc2a-dc0a21d9b12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15299f0a-410b-42c1-85f2-f5ef196704fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             ('transformer.h.0.attn.masked_bias', tensor(-10000.)),\n",
    "             ('transformer.h.1.attn.masked_bias', tensor(-10000.)),\n",
    "             ('transformer.h.4.attn.masked_bias', tensor(-10000.)),\n",
    "        \n",
    "        .attn.masked_bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "115a678b-114f-4d58-8330-44b2f1dc0127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer.wte.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.wpe.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.0.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.0.ln_1.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.0.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.0.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.0.attn.c_attn.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.0.attn.c_attn.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.0.attn.c_proj.weight',\n",
       "              tensor([[ 0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.0.attn.c_proj.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.0.ln_2.weight', tensor([0,  ..., 1])),\n",
       "             ('transformer.h.0.ln_2.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.0.mlp.c_fc.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.0.mlp.c_fc.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.0.mlp.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.0.mlp.c_proj.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.1.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.1.ln_1.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.1.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.1.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.1.attn.c_attn.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.1.attn.c_attn.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.1.attn.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.1.attn.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.1.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.1.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.1.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.1.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.1.mlp.c_proj.weight',\n",
       "              tensor([[ 0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.1.mlp.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.2.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.2.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.2.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.2.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.2.attn.c_attn.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.2.attn.c_attn.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.2.attn.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.2.attn.c_proj.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.2.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.2.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.2.mlp.c_fc.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.2.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.2.mlp.c_proj.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.2.mlp.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.3.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.3.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.3.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.3.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.3.attn.c_attn.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.3.attn.c_attn.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.3.attn.c_proj.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.3.attn.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.3.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.3.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.3.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.3.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.3.mlp.c_proj.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.3.mlp.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.4.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.4.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.4.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.4.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.4.attn.c_attn.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.4.attn.c_attn.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.4.attn.c_proj.weight',\n",
       "              tensor([[0,  ..., 0],\n",
       "                      ...,\n",
       "                      [0,  ..., 0]])),\n",
       "             ('transformer.h.4.attn.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.4.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.4.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.4.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.4.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.4.mlp.c_proj.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.4.mlp.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.5.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.5.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.5.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.5.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.5.attn.c_attn.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.5.attn.c_attn.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.5.attn.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.5.attn.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.5.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.5.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.5.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.5.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.5.mlp.c_proj.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.5.mlp.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.6.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.6.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.6.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.6.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.6.attn.c_attn.weight',\n",
       "              tensor([[ 0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.6.attn.c_attn.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.6.attn.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.6.attn.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.6.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.6.ln_2.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.6.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.6.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.6.mlp.c_proj.weight',\n",
       "              tensor([[ 0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.6.mlp.c_proj.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.7.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.7.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.7.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.7.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.7.attn.c_attn.weight',\n",
       "              tensor([[ 1e-01,  ..., -1e-01],\n",
       "                      ...,\n",
       "                      [ 1e-04,  ..., -1e-02]])),\n",
       "             ('transformer.h.7.attn.c_attn.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.7.attn.c_proj.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.7.attn.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.7.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.7.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.7.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.7.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.7.mlp.c_proj.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.7.mlp.c_proj.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.8.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.8.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.8.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.8.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.8.attn.c_attn.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.8.attn.c_attn.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.8.attn.c_proj.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.8.attn.c_proj.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.8.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.8.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.8.mlp.c_fc.weight',\n",
       "              tensor([[ 0,  ..., -0],\n",
       "                      ...,\n",
       "                      [-0,  ...,  0]])),\n",
       "             ('transformer.h.8.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.8.mlp.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.8.mlp.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.9.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.9.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.9.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.9.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.9.attn.c_attn.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.9.attn.c_attn.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.9.attn.c_proj.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.9.attn.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.9.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.9.ln_2.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.9.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.9.mlp.c_fc.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.9.mlp.c_proj.weight',\n",
       "              tensor([[0,  ..., 0],\n",
       "                      ...,\n",
       "                      [0,  ..., 0]])),\n",
       "             ('transformer.h.9.mlp.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.10.ln_1.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.10.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.10.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.10.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.10.attn.c_attn.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.10.attn.c_attn.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.10.attn.c_proj.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.10.attn.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.10.ln_2.weight', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.10.ln_2.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.10.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [-0,  ..., -0]])),\n",
       "             ('transformer.h.10.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.10.mlp.c_proj.weight',\n",
       "              tensor([[ 0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ..., -0]])),\n",
       "             ('transformer.h.10.mlp.c_proj.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.11.ln_1.weight', tensor([1,  ..., 0])),\n",
       "             ('transformer.h.11.ln_1.bias', tensor([0,  ..., 0])),\n",
       "             ('transformer.h.11.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.11.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.11.attn.c_attn.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.11.attn.c_attn.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.11.attn.c_proj.weight',\n",
       "              tensor([[ 0,  ..., -0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.11.attn.c_proj.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.h.11.ln_2.weight', tensor([0,  ..., 1])),\n",
       "             ('transformer.h.11.ln_2.bias', tensor([-0,  ...,  0])),\n",
       "             ('transformer.h.11.mlp.c_fc.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]])),\n",
       "             ('transformer.h.11.mlp.c_fc.bias', tensor([-0,  ..., -0])),\n",
       "             ('transformer.h.11.mlp.c_proj.weight',\n",
       "              tensor([[0,  ..., 0],\n",
       "                      ...,\n",
       "                      [0,  ..., 0]])),\n",
       "             ('transformer.h.11.mlp.c_proj.bias', tensor([ 0,  ..., -0])),\n",
       "             ('transformer.ln_f.weight', tensor([1,  ..., 1])),\n",
       "             ('transformer.ln_f.bias', tensor([0,  ..., 0])),\n",
       "             ('lm_head.weight',\n",
       "              tensor([[-0,  ...,  0],\n",
       "                      ...,\n",
       "                      [ 0,  ...,  0]]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4f73b-74b4-4ea4-908f-202d941b1ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc2e45-0b25-4e1f-8e96-592e57aff902",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae4d62-edf4-4d67-adbd-2857b58fe547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39029cd-3407-4645-bce5-e4a1eb8ce4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d46086-fae1-4b37-96da-4350c7528b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef19b0d-63ee-413d-b4e6-f6f5ade95763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ce324-9b9d-4e1b-8d25-77cb3759c5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567c208c-5563-48d7-86a7-c46c5d71e891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6058cc-0ec1-4a2c-a55e-3657f2adc538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51efe6c2-6fea-40d7-a3aa-9015bf89536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1.54646456)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
