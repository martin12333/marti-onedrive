{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451f0e6-d114-426e-9e7a-5b7f271727d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32ed926-6789-4c08-95ce-edd54d974acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mm ... small edits by M. M.\n",
    "# (#aaa #aaaa #aaaa ... \"attention\", \"importance\" marks, just for M. M.)\n",
    "#mm-todo-tweak #aaaa\n",
    "\n",
    "#mm\n",
    "import torch\n",
    "torch.set_printoptions(profile='short')\n",
    "#%precision 2\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_printoptions.html\n",
    "#torch.set_printoptions(precision=0)\n",
    "torch.set_printoptions(threshold=7)\n",
    "torch.set_printoptions(edgeitems=3)\n",
    "torch.set_printoptions(edgeitems=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2247eb8e-c55f-4338-a72a-b776199312c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     D:\\conda\n",
      "jupsci_nonpip310         D:\\conda\\envs\\jupsci_nonpip310\n",
      "pip310                *  D:\\conda\\envs\\pip310\n",
      "torch_nonpip310          D:\\conda\\envs\\torch_nonpip310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819080d3-550e-4fa4-9f85-98fd8a9d7cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4e286-dffe-4608-8666-82da3a7a4736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "615e646c-4f5f-4513-9f87-731f7447344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"d:/ai/my235r/runs\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b32f1b-6981-43f2-92f8-0e6aa9ee5544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b468f3a4-ebe8-4d54-84d3-595c05a7c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/fxmarty/tiny-testing-gpt2-remote-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49282225-e2d2-4530-8e3e-cd418c2eaafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\pip310\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead   #,  TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\")\n",
    "\n",
    "####model = TFAutoModel.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  \n",
    "model = AutoModelWithLMHead.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9ae72-e4d2-4c3f-a11d-66fa1945487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/sshleifer/tiny-gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "830f984e-fe05-4763-99cd-ff6183b8c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM  #, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained(\"sshleifer/tiny-gpt2\"  ) # ,  from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94916d0d-0f47-47da-a893-872b1929ae49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd36ac6-dfb1-489d-bd82-49e75ee0259f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c689fa-57b9-40a0-893d-bca77c74b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2')  # or any other checkpoint\n",
    "word_embeddings = model.transformer.wte.weight  # Word Token Embeddings \n",
    "position_embeddings = model.transformer.wpe.weight  # Word Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1c9275-20c1-40d0-9f08-914b11f07f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99dc038-c6bf-430a-bbef-b7338a9e2b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad54016-6378-4f9f-878d-8da60c6e65b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=32000, minmax=(-0.10435799, 0.082304895), mean=0.00017225943, variance=0.00039630984347471386, skewness=0.0001497342779539685, kurtosis=0.03427094952117349)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(word_embeddings.flatten().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f7d5bd-c634-493f-bc58-9c872c952914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=16384, minmax=(-0.07737117, 0.075206414), mean=0.00015542598, variance=0.0003896276789154535, skewness=-0.014906239080622023, kurtosis=-0.022284417011880553)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(position_embeddings.flatten().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc1b73-de73-42a1-b841-1c438402e9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32ea1ab-a466-4c19-9253-6e9abd4bad54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(1000, 32)\n",
       "    (wpe): Embedding(512, 32)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=1000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf863da2-7fca-4a83-8309-052692fcf095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "for layer in model.children():\n",
    "    if hasattr(layer, 'out_features'):\n",
    "        print(layer.out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8d0674d-c4e2-4cd9-a383-8332bd009880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85c69b-c65c-47d0-a72b-daac4b30f488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4212cc-7232-447d-9ba0-6920ab54fbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7352959-2c4e-4706-87f1-bfabeab13583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c586d3-9dcc-4a1d-9e41-493e74c3f299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93d183f-0b6f-47ac-9b20-a8766fb72776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight : (1000, 32)\n",
      "transformer.wpe.weight : (512, 32)\n",
      "transformer.h.0.ln_1.weight : (32,)\n",
      "transformer.h.0.ln_1.bias : (32,)\n",
      "transformer.h.0.attn.c_attn.weight : (32, 96)\n",
      "transformer.h.0.attn.c_attn.bias : (96,)\n",
      "transformer.h.0.attn.c_proj.weight : (32, 32)\n",
      "transformer.h.0.attn.c_proj.bias : (32,)\n",
      "transformer.h.0.ln_2.weight : (32,)\n",
      "transformer.h.0.ln_2.bias : (32,)\n",
      "transformer.h.0.mlp.c_fc.weight : (32, 128)\n",
      "transformer.h.0.mlp.c_fc.bias : (128,)\n",
      "transformer.h.0.mlp.c_proj.weight : (128, 32)\n",
      "transformer.h.0.mlp.c_proj.bias : (32,)\n",
      "transformer.h.1.ln_1.weight : (32,)\n",
      "transformer.h.1.ln_1.bias : (32,)\n",
      "transformer.h.1.attn.c_attn.weight : (32, 96)\n",
      "transformer.h.1.attn.c_attn.bias : (96,)\n",
      "transformer.h.1.attn.c_proj.weight : (32, 32)\n",
      "transformer.h.1.attn.c_proj.bias : (32,)\n",
      "transformer.h.1.ln_2.weight : (32,)\n",
      "transformer.h.1.ln_2.bias : (32,)\n",
      "transformer.h.1.mlp.c_fc.weight : (32, 128)\n",
      "transformer.h.1.mlp.c_fc.bias : (128,)\n",
      "transformer.h.1.mlp.c_proj.weight : (128, 32)\n",
      "transformer.h.1.mlp.c_proj.bias : (32,)\n",
      "transformer.h.2.ln_1.weight : (32,)\n",
      "transformer.h.2.ln_1.bias : (32,)\n",
      "transformer.h.2.attn.c_attn.weight : (32, 96)\n",
      "transformer.h.2.attn.c_attn.bias : (96,)\n",
      "transformer.h.2.attn.c_proj.weight : (32, 32)\n",
      "transformer.h.2.attn.c_proj.bias : (32,)\n",
      "transformer.h.2.ln_2.weight : (32,)\n",
      "transformer.h.2.ln_2.bias : (32,)\n",
      "transformer.h.2.mlp.c_fc.weight : (32, 128)\n",
      "transformer.h.2.mlp.c_fc.bias : (128,)\n",
      "transformer.h.2.mlp.c_proj.weight : (128, 32)\n",
      "transformer.h.2.mlp.c_proj.bias : (32,)\n",
      "transformer.h.3.ln_1.weight : (32,)\n",
      "transformer.h.3.ln_1.bias : (32,)\n",
      "transformer.h.3.attn.c_attn.weight : (32, 96)\n",
      "transformer.h.3.attn.c_attn.bias : (96,)\n",
      "transformer.h.3.attn.c_proj.weight : (32, 32)\n",
      "transformer.h.3.attn.c_proj.bias : (32,)\n",
      "transformer.h.3.ln_2.weight : (32,)\n",
      "transformer.h.3.ln_2.bias : (32,)\n",
      "transformer.h.3.mlp.c_fc.weight : (32, 128)\n",
      "transformer.h.3.mlp.c_fc.bias : (128,)\n",
      "transformer.h.3.mlp.c_proj.weight : (128, 32)\n",
      "transformer.h.3.mlp.c_proj.bias : (32,)\n",
      "transformer.h.4.ln_1.weight : (32,)\n",
      "transformer.h.4.ln_1.bias : (32,)\n",
      "transformer.h.4.attn.c_attn.weight : (32, 96)\n",
      "transformer.h.4.attn.c_attn.bias : (96,)\n",
      "transformer.h.4.attn.c_proj.weight : (32, 32)\n",
      "transformer.h.4.attn.c_proj.bias : (32,)\n",
      "transformer.h.4.ln_2.weight : (32,)\n",
      "transformer.h.4.ln_2.bias : (32,)\n",
      "transformer.h.4.mlp.c_fc.weight : (32, 128)\n",
      "transformer.h.4.mlp.c_fc.bias : (128,)\n",
      "transformer.h.4.mlp.c_proj.weight : (128, 32)\n",
      "transformer.h.4.mlp.c_proj.bias : (32,)\n",
      "transformer.ln_f.weight : (32,)\n",
      "transformer.ln_f.bias : (32,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for l in list(model.named_parameters()):\n",
    "    print(l[0], ':', l[1].detach().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745dabd-1c08-40b3-8b2b-2f3d634ad3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf3f1aa-338b-4b73-8c5a-7dfa6b7078e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32000])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d4619-514b-4cc5-96fa-5c7840ca7a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b486e-5b50-46ef-b836-4ad4a3e32170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70e1a95a-99e2-4e6f-b560-9432d614ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ids = torch.tensor([5, 3], dtype=torch.int32)\n",
    "x = torch.tensor([5, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0a0ba61-44ec-440a-b0eb-8c3379ef8a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'stat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'stat'"
     ]
    }
   ],
   "source": [
    "torch.stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45629ef0-c58e-4ce9-9e38-df5b77869fc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('transformer.wte.weight',\n",
       "              tensor([[0.01,  ..., 0.05],\n",
       "                      ...,\n",
       "                      [0.01,  ..., 0.03]])),\n",
       "             ('transformer.wpe.weight',\n",
       "              tensor([[-0.02,  ..., -0.02],\n",
       "                      ...,\n",
       "                      [-0.03,  ...,  0.02]])),\n",
       "             ('transformer.h.0.ln_1.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.0.ln_1.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.0.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.0.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.0.attn.c_attn.weight',\n",
       "              tensor([[ 0.01,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [ 0.04,  ...,  0.02]])),\n",
       "             ('transformer.h.0.attn.c_attn.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.0.attn.c_proj.weight',\n",
       "              tensor([[-0.01,  ..., -0.00],\n",
       "                      ...,\n",
       "                      [-0.01,  ..., -0.01]])),\n",
       "             ('transformer.h.0.attn.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.0.ln_2.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.0.ln_2.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.0.mlp.c_fc.weight',\n",
       "              tensor([[-0.02,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [ 0.03,  ...,  0.01]])),\n",
       "             ('transformer.h.0.mlp.c_fc.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.0.mlp.c_proj.weight',\n",
       "              tensor([[ 0.00,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [-0.01,  ..., -0.00]])),\n",
       "             ('transformer.h.0.mlp.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.1.ln_1.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.1.ln_1.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.1.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.1.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.1.attn.c_attn.weight',\n",
       "              tensor([[0.01,  ..., 0.01],\n",
       "                      ...,\n",
       "                      [0.01,  ..., 0.02]])),\n",
       "             ('transformer.h.1.attn.c_attn.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.1.attn.c_proj.weight',\n",
       "              tensor([[ 0.00,  ...,  0.01],\n",
       "                      ...,\n",
       "                      [ 0.01,  ..., -0.00]])),\n",
       "             ('transformer.h.1.attn.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.1.ln_2.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.1.ln_2.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.1.mlp.c_fc.weight',\n",
       "              tensor([[ 0.02,  ...,  0.02],\n",
       "                      ...,\n",
       "                      [ 0.01,  ..., -0.01]])),\n",
       "             ('transformer.h.1.mlp.c_fc.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.1.mlp.c_proj.weight',\n",
       "              tensor([[-0.00,  ...,  0.00],\n",
       "                      ...,\n",
       "                      [-0.00,  ..., -0.01]])),\n",
       "             ('transformer.h.1.mlp.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.2.ln_1.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.2.ln_1.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.2.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.2.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.2.attn.c_attn.weight',\n",
       "              tensor([[-0.01,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [ 0.01,  ...,  0.02]])),\n",
       "             ('transformer.h.2.attn.c_attn.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.2.attn.c_proj.weight',\n",
       "              tensor([[0.00,  ..., 0.01],\n",
       "                      ...,\n",
       "                      [0.00,  ..., 0.01]])),\n",
       "             ('transformer.h.2.attn.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.2.ln_2.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.2.ln_2.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.2.mlp.c_fc.weight',\n",
       "              tensor([[ 0.02,  ..., -0.00],\n",
       "                      ...,\n",
       "                      [-0.01,  ...,  0.04]])),\n",
       "             ('transformer.h.2.mlp.c_fc.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.2.mlp.c_proj.weight',\n",
       "              tensor([[-0.00,  ...,  0.01],\n",
       "                      ...,\n",
       "                      [-0.00,  ...,  0.01]])),\n",
       "             ('transformer.h.2.mlp.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.3.ln_1.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.3.ln_1.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.3.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.3.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.3.attn.c_attn.weight',\n",
       "              tensor([[-0.01,  ..., -0.02],\n",
       "                      ...,\n",
       "                      [ 0.00,  ..., -0.01]])),\n",
       "             ('transformer.h.3.attn.c_attn.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.3.attn.c_proj.weight',\n",
       "              tensor([[ 0.01,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [ 0.02,  ...,  0.00]])),\n",
       "             ('transformer.h.3.attn.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.3.ln_2.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.3.ln_2.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.3.mlp.c_fc.weight',\n",
       "              tensor([[-0.01,  ...,  0.01],\n",
       "                      ...,\n",
       "                      [-0.03,  ..., -0.02]])),\n",
       "             ('transformer.h.3.mlp.c_fc.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.3.mlp.c_proj.weight',\n",
       "              tensor([[ 0.00,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [ 0.01,  ..., -0.00]])),\n",
       "             ('transformer.h.3.mlp.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.4.ln_1.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.4.ln_1.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.4.attn.bias',\n",
       "              tensor([[[[ True,  ..., False],\n",
       "                        ...,\n",
       "                        [ True,  ...,  True]]]])),\n",
       "             ('transformer.h.4.attn.masked_bias', tensor(-10000.)),\n",
       "             ('transformer.h.4.attn.c_attn.weight',\n",
       "              tensor([[0.00,  ..., 0.02],\n",
       "                      ...,\n",
       "                      [0.00,  ..., 0.03]])),\n",
       "             ('transformer.h.4.attn.c_attn.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.4.attn.c_proj.weight',\n",
       "              tensor([[ 0.00,  ...,  0.00],\n",
       "                      ...,\n",
       "                      [ 0.01,  ..., -0.01]])),\n",
       "             ('transformer.h.4.attn.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.4.ln_2.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.h.4.ln_2.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.4.mlp.c_fc.weight',\n",
       "              tensor([[ 0.02,  ..., -0.00],\n",
       "                      ...,\n",
       "                      [ 0.01,  ...,  0.03]])),\n",
       "             ('transformer.h.4.mlp.c_fc.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.h.4.mlp.c_proj.weight',\n",
       "              tensor([[-0.01,  ..., -0.01],\n",
       "                      ...,\n",
       "                      [ 0.01,  ...,  0.00]])),\n",
       "             ('transformer.h.4.mlp.c_proj.bias', tensor([0.,  ..., 0.])),\n",
       "             ('transformer.ln_f.weight', tensor([1.,  ..., 1.])),\n",
       "             ('transformer.ln_f.bias', tensor([0.,  ..., 0.])),\n",
       "             ('lm_head.weight',\n",
       "              tensor([[0.01,  ..., 0.05],\n",
       "                      ...,\n",
       "                      [0.01,  ..., 0.03]]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729a18b-ba05-4c87-90ca-92134cee6786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57d722-f32c-4e53-84b4-8fa21f24cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model,    input_to_model=ids  )\n",
    "###writer.add_graph(model, input_to_model=torch.randn(1, 3, 224, 224))\n",
    "\n",
    "# ModuleNotFoundError: No module named 'caffe2'\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5bd8f26-e023-4ed9-915b-3fca7a40aab3",
   "metadata": {},
   "source": [
    "#model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "## This model only exists in PyTorch, so we use the `from_pt` flag to import that model in TensorFlow.\n",
    "#model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af3678-552e-4382-b5bf-64f7295b2c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afa5f9-5003-4067-81e9-b0a495d02a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef46844-a31a-4b6e-bccf-408ec9b74428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b3882a-0f14-407d-9999-4d25f40d79ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
