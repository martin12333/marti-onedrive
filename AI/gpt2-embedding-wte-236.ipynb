{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233793d5-d07e-4301-b43f-dac448acebc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9563d48-5ab1-42f6-b799-0daa9d888943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714c16d-7211-445b-921d-9142a4808b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffc6790d-1884-4690-9f7a-da5dc34bf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mm ... small edits by M. M.\n",
    "# (#aaa #aaaa #aaaa ... \"attention\", \"importance\" marks, just for M. M.)\n",
    "#mm-todo-tweak #aaaa\n",
    "\n",
    "#mm\n",
    "import torch\n",
    "torch.set_printoptions(profile='short')\n",
    "#%precision 2\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_printoptions.html\n",
    "torch.set_printoptions(precision=0)\n",
    "torch.set_printoptions(threshold=7)\n",
    "torch.set_printoptions(edgeitems=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513ff0c-094f-4423-b8ce-90df63e3a0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615e646c-4f5f-4513-9f87-731f7447344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-236\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10100c8a-67b1-4ba1-9c76-0e49197ae7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "971bcd86-2507-4039-b032-c7150b42bc66",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3109400545.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://huggingface.co/openai/gpt2\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://huggingface.co/gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3f7a39-16b3-4193-baa8-0cff09e6daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53481bc-497f-4869-943c-d0a7344e35d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "121f6acf-87c7-4c7d-a42c-c0ac66756d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2')  # or any other checkpoint\n",
    "word_embeddings = model.transformer.wte.weight  # Word Token Embeddings \n",
    "position_embeddings = model.transformer.wpe.weight  # Word Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469fdaa4-2172-4598-803e-c9fdbb34ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              27 Dir(s)   2,164,035,584 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir d: | findstr -i free\n",
    "#              27 Dir(s)   2,164,035,584 bytes free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "015f9415-0cd0-444e-87f7-c341139deb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.fast.ai/callback.tensorboard.html#gpt2\n",
    "layer = model.transformer.wte\n",
    "vocab_dict = tokenizer.get_vocab()\n",
    "\n",
    "vocab = [k for k, v in sorted(vocab_dict.items(), key=lambda x: x[1])]\n",
    "\n",
    "#projector_word_embeddings(layer=layer, vocab=vocab, limit=2000, log_dir=\n",
    "                          \n",
    "#                          Path.home()/'tmp'/'runs'/'transformers')\n",
    "#writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-236\")\n",
    "limit=-1\n",
    "start=0\n",
    "if True:\n",
    "    emb = layer.weight\n",
    "    end = start + limit if limit >= 0 else -1\n",
    "    \n",
    "    writer.add_embedding(emb[start:end], metadata=vocab[start:end] ) #, label_img=img[start:end])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e279a18d-75d8-4158-b2e8-f7c4ee965a77",
   "metadata": {},
   "source": [
    "# https://github.com/fastai/fastai/blob/master/nbs/70a_callback.tensorboard.ipynb\n",
    "\n",
    "#|export\n",
    "def projector_word_embeddings(learn=None, layer=None, vocab=None, limit=-1, start=0, log_dir=None):\n",
    "    \"Extracts and exports word embeddings from language models embedding layers\"\n",
    "    if not layer:\n",
    "        if   isinstance(learn, LMLearner):   layer = learn.model[0].encoder\n",
    "        elif isinstance(learn, TextLearner): layer = learn.model[0].module.encoder\n",
    "    emb = layer.weight\n",
    "    img = torch.full((len(emb),3,8,8), 0.7)\n",
    "    vocab = learn.dls.vocab[0] if vocab == None else vocab\n",
    "    vocab = list(map(lambda x: f'{x}_', vocab))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    end = start + limit if limit >= 0 else -1\n",
    "    writer.add_embedding(emb[start:end], metadata=vocab[start:end], label_img=img[start:end])\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff4a1243-5d6c-487e-b26c-362abc4bc18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e5fe1-ec72-4f21-ad36-b8132bc29503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80c7786a-598d-4247-8dc5-b0129268a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.24,  0.80, -0.32, -0.85],\n",
      "         [-0.07,  1.78,  1.52, -0.58],\n",
      "         [ 0.24, -0.55, -2.17,  0.49]],\n",
      "\n",
      "        [[ 0.36,  0.24, -1.20,  1.34],\n",
      "         [-0.68, -1.02,  0.44, -0.17],\n",
      "         [-0.07, -1.07,  0.49,  0.42]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.17"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmilanutil import *\n",
    "## ⚠ I forgot to restart the jupyter kernel after changing the module\n",
    "\n",
    "x = torch.randn(2,3, 4)\n",
    "print(x)\n",
    "\n",
    "mmptmaxabs(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0463ae3-81b2-4183-b95f-a29bdb1320db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53399943-0515-4ec5-aac0-f864cc2cd4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġpre', (0, 4)),\n",
       " ('Ġspace', (4, 10)),\n",
       " ('ĠHello', (10, 16)),\n",
       " (',', (16, 17)),\n",
       " ('ĉĠčĊčĊĠ', (17, 24)),\n",
       " ('Ġhow', (24, 28)),\n",
       " ('Ġare', (28, 32)),\n",
       " ('Ġ', (32, 33)),\n",
       " ('Ġyou', (33, 37)),\n",
       " ('?', (37, 38)),\n",
       " ('Ċ', (38, 39))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\" pre space Hello,\\t \\r\\n\\r\\n  how are  you?\\n\")\n",
    "# pre space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0bf0c47-0709-4d03-a615-362ee1a58a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[662, 2272, 3914, 338, 1332, 428, 11241, 7509, 13]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\" pre space Let's test this tokenizer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cca1f4-7af5-4e97-8fc7-00d492ba714d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)\n",
    "type(tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99ebbe-fbf4-43aa-b9a3-f31b56458ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e6e22-1e19-43c8-a890-41ad586e83ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b2974-d857-420c-9967-ed7248c58226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb21a41-4a3a-4246-9817-3bfd8fd84c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1438518-555e-4dc7-be47-d21839bf1b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c0453-5c9e-45d6-9c19-580eed5dc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what mistake is in the re.sub\n",
    "\n",
    "#gpt3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
