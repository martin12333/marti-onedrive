{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc6790d-1884-4690-9f7a-da5dc34bf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mm ... small edits by M. M.\n",
    "# (#aaa #aaaa #aaaa ... \"attention\", \"importance\" marks, just for M. M.)\n",
    "#mm-todo-tweak #aaaa\n",
    "\n",
    "#mm\n",
    "import torch\n",
    "torch.set_printoptions(profile='short')\n",
    "##%precision 2\n",
    "# https://pytorch.org/docs/stable/generated/torch.set_printoptions.html\n",
    "torch.set_printoptions(precision=0)\n",
    "torch.set_printoptions(precision=2)\n",
    "torch.set_printoptions(threshold=7)\n",
    "torch.set_printoptions(edgeitems=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "615e646c-4f5f-4513-9f87-731f7447344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-50k\")\n",
    "#writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-20k\")\n",
    "#writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-10k\")\n",
    "writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-1k\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa1780-f844-41ef-9923-342924d92826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef695538-56b6-4ae7-b1cd-cf60f5141a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\pip310\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/fxmarty/tiny-testing-gpt2-remote-code\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead   #,  TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\")\n",
    "\n",
    "####model = TFAutoModel.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  \n",
    "model = AutoModelWithLMHead.from_pretrained(\"fxmarty/tiny-testing-gpt2-remote-code\" ) #  ,  from_pt=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c705001c-9758-4e97-bcb8-de23e737e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/sshleifer/tiny-gpt2\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM  #, TFAutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/tiny-gpt2\")\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained(\"sshleifer/tiny-gpt2\"  ) # ,  from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3f7a39-16b3-4193-baa8-0cff09e6daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/gpt2\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe74fb0-8341-49c4-ab12-dc6388addf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d8474a-daea-4842-ac98-f30926f4c5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "358838a6-9806-40b2-a7f0-4c28ae1b5f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf69bfba-ed88-4166-ab5b-521114aa6d99",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(1000, 32)\n",
       "    (wpe): Embedding(512, 32)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=1000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3254d15b-37c5-49bc-b280-e79ee0f7b644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=50257, bias=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head #aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9747905c-a8a6-4e99-ba92-eda90a5766c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_fill_padding_idx_with_zero',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'embedding_dim',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'max_norm',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'norm_type',\n",
       " 'num_embeddings',\n",
       " 'padding_idx',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'scale_grad_by_freq',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'sparse',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.transformer.wte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6b0d47-376c-4732-b47b-2c5f8b93789c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "121f6acf-87c7-4c7d-a42c-c0ac66756d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2')  # or any other checkpoint\n",
    "word_embeddings = model.transformer.wte.weight  # Word Token Embeddings \n",
    "position_embeddings = model.transformer.wpe.weight  # Word Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c881d09-d5aa-46c9-b57e-120655d08f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469fdaa4-2172-4598-803e-c9fdbb34ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              27 Dir(s)     863,698,944 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir d: | findstr -i free\n",
    "#              27 Dir(s)   2,164,035,584 bytes free\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "015f9415-0cd0-444e-87f7-c341139deb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "# https://docs.fast.ai/callback.tensorboard.html#gpt2\n",
    "\n",
    "layer = model.transformer.wte\n",
    "vocab_dict = tokenizer.get_vocab()\n",
    "\n",
    "#aaaa\n",
    "vocab = [k for k, v in sorted(vocab_dict.items(), key=lambda x: x[1])]\n",
    "\n",
    "#projector_word_embeddings(layer=layer, vocab=vocab, limit=2000, log_dir=            \n",
    "#                          Path.home()/'tmp'/'runs'/'transformers')\n",
    "#writer = SummaryWriter(\"d:/ai/gpt2-embedding-wte-236\")\n",
    "limit= 1000 # 20000 # 10000 # -1  #300 # 100 # -1\n",
    "start=0\n",
    "if True:\n",
    "    emb = layer.weight\n",
    "    print(emb.shape)\n",
    "    end = start + limit if limit >= 0 else -1\n",
    "    \n",
    "    writer.add_embedding(emb[start:end], metadata=vocab[start:end] ) #, label_img=img[start:end])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc231ae-d886-4c8d-87c9-802dc1de997b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e279a18d-75d8-4158-b2e8-f7c4ee965a77",
   "metadata": {},
   "source": [
    "# https://github.com/fastai/fastai/blob/master/nbs/70a_callback.tensorboard.ipynb\n",
    "\n",
    "#|export\n",
    "def projector_word_embeddings(learn=None, layer=None, vocab=None, limit=-1, start=0, log_dir=None):\n",
    "    \"Extracts and exports word embeddings from language models embedding layers\"\n",
    "    if not layer:\n",
    "        if   isinstance(learn, LMLearner):   layer = learn.model[0].encoder\n",
    "        elif isinstance(learn, TextLearner): layer = learn.model[0].module.encoder\n",
    "    emb = layer.weight\n",
    "    img = torch.full((len(emb),3,8,8), 0.7)\n",
    "    vocab = learn.dls.vocab[0] if vocab == None else vocab\n",
    "    vocab = list(map(lambda x: f'{x}_', vocab))\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    end = start + limit if limit >= 0 else -1\n",
    "    writer.add_embedding(emb[start:end], metadata=vocab[start:end], label_img=img[start:end])\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff4a1243-5d6c-487e-b26c-362abc4bc18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7a5e5fe1-ec72-4f21-ad36-b8132bc29503",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.transformer.wte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af1b8cec-7d5d-41a0-b9a9-86e486187ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.sparse.Embedding"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.transformer.wpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "857ae24a-56f2-4597-acbb-9a3b1dfb1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.linear.Linear"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80c7786a-598d-4247-8dc5-b0129268a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10435798764228821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10435798764228821"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmilanutil import *\n",
    "## ⚠ I forgot to restart the jupyter kernel after changing the module\n",
    "\n",
    "print(mmptmaxabs(model.transformer.wte.weight))\n",
    "mmptmaxabs(model.lm_head.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0463ae3-81b2-4183-b95f-a29bdb1320db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "53399943-0515-4ec5-aac0-f864cc2cd4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ġpre', (0, 4)),\n",
       " ('Ġspace', (4, 10)),\n",
       " ('ĠHello', (10, 16)),\n",
       " (',', (16, 17)),\n",
       " ('ĉĠčĊčĊĠ', (17, 24)),\n",
       " ('Ġhow', (24, 28)),\n",
       " ('Ġare', (28, 32)),\n",
       " ('Ġ', (32, 33)),\n",
       " ('Ġyou', (33, 37)),\n",
       " ('?', (37, 38)),\n",
       " ('Ċ', (38, 39))]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(\" pre space Hello,\\t \\r\\n\\r\\n  how are  you?\\n\")\n",
    "# pre space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0bf0c47-0709-4d03-a615-362ee1a58a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[577, 405, 571, 317, 269, 7, 83, 194, 328, 526, 227, 75, 213, 529, 199, 14]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\" pre space Let's test this tokenizer.\"\n",
    "tokenizer.encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "667edcfb-3f5d-4e72-88f8-90feabf90a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[577,  ...,  14]]), 'attention_mask': tensor([[1,  ..., 1]])}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input_gpt2 = tokenizer(text , return_tensors='pt')\n",
    "encoded_input_gpt2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "462b2202-938b-404c-8426-2ed59a8b8bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.CausalLMOutputWithCrossAttentions"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://discuss.pytorch.org/t/gpt2-and-bert-embeddings-hugging-face/168989\n",
    "output_gpt2 = model(**encoded_input_gpt2)\n",
    "type(output_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca62b8-ceb2-42b2-a8fa-3870fbfd85ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2529e19-1e9e-4570-8629-50560cb63303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f55a7-acb3-48ab-ad9f-f0b431efda80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "89d584bc-d94f-479b-b771-a04b018c0833",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 2480-D21D\n",
      "\n",
      " Directory of C:\\Users\\marti\\OneDrive\\AI\n",
      "\n",
      "04/29/2023  21:08             3,660 #openai.e.f8.sh#\n",
      "06/04/2023  01:57    <DIR>          .\n",
      "06/02/2023  21:37    <DIR>          ..\n",
      "05/21/2023  11:09    <DIR>          .conda\n",
      "05/06/2023  20:28                73 .condarc\n",
      "03/10/2021  16:51             1,799 .gitignore\n",
      "06/03/2023  19:49    <DIR>          .ipynb_checkpoints\n",
      "05/31/2023  17:21                 0 __init__.py\n",
      "04/29/2023  21:11            43,023 1models.json\n",
      "05/17/2023  04:49               797 abcdef.f8.tokenizer.json\n",
      "05/22/2023  11:39             5,238 ai-212.e.f8.py\n",
      "05/10/2022  20:22             1,395 asktutor-3.prompt\n",
      "02/28/2021  22:34            13,868 AutoTokenizer-1.ipynb\n",
      "02/27/2021  16:45    <DIR>          bart\n",
      "05/10/2022  20:22               688 bash-one-liner-generator-from-natural-language-1.prompt\n",
      "01/30/2021  16:32           247,682 Beginner's Guide to Retrain GPT-2 (117M) to Generate Custom Text Content _ by Ng Wai Foong _ AI Innovation _ Medium.html\n",
      "05/17/2023  01:19    <DIR>          bert\n",
      "03/05/2019  04:23            18,176 BERT_blog - .json\n",
      "03/05/2019  04:23            18,176 BERT_blog.ipynb\n",
      "09/16/2021  21:17           124,000 calls-20210916203915.xml\n",
      "12/23/2022  04:45             2,225 chatgpt.txt.md\n",
      "05/18/2023  07:25             2,513 chat-with-people-about-ai.md\n",
      "05/05/2023  01:52               243 chat-with-people-about-ai--selected--public.f8.md\n",
      "05/06/2023  20:09           346,285 Clean_Transformer_Demo_Template.ipynb\n",
      "05/17/2023  03:45    <DIR>          code-search-net-tokenizer1\n",
      "12/23/2022  04:30             1,205 codex-javascript-sandbox.md\n",
      "06/01/2023  20:29             1,177 colab.research.google.com--intro.e.f8.py\n",
      "06/01/2023  19:17            80,944 colab_pip_list(1).ipynb\n",
      "06/02/2023  21:45            12,004 conda,pip,mamba,ai-python.e.f8.sh\n",
      "05/27/2023  20:36             4,328 conda----10jupsci_nonpip310.e.f8.sh\n",
      "05/27/2023  20:42             7,491 conda----20torch_nonpip310.e.f8.sh\n",
      "05/30/2023  14:06               476 debug.log\n",
      "05/12/2023  02:59           412,065 EasyTransformer_Demo.ipynb\n",
      "05/22/2023  07:48    <DIR>          fuj~\n",
      "05/10/2022  20:22             1,188 generate-jq-from-json-1.prompt\n",
      "02/24/2021  17:02           295,906 gpt-2_domains.txt at master ú openai_gpt-2.html\n",
      "06/15/2022  18:43             6,271 gpt-2-1-antid.txt.md\n",
      "06/04/2023  01:57            28,741 gpt2-embedding-wte-236.ipynb\n",
      "02/28/2021  18:16             3,825 gpt-2-large-2.txt.md\n",
      "02/28/2021  16:46             2,162 gpt-2-med-2.txt.md\n",
      "02/24/2021  18:01         1,042,301 gpt2-vocab.json\n",
      "05/15/2023  03:40               921 gpt3-davinci--emacs-question.txt.md\n",
      "05/13/2023  00:27             5,838 gpt3-davinci--neuroscope-question.txt.md\n",
      "05/12/2023  23:17            29,784 gpt3-openai.txt.md\n",
      "05/01/2023  18:58             2,313 GPT-4-step-by-step.f8.md\n",
      "05/29/2023  12:44             1,568 gpt-about-fortran.f8.md\n",
      "05/29/2023  12:46               984 gpt-about-mathica.f8.md\n",
      "05/11/2023  00:02             1,521 gpt-from-scratch.e.f8.py\n",
      "01/09/2021  03:05             2,826 gradle.yml\n",
      "02/23/2021  13:32            25,729 hf-2.ipynb\n",
      "03/23/2021  18:23            38,099 hf-3 - Copy.ipynb\n",
      "02/05/2021  18:46            25,301 hf38-1.ipynb\n",
      "02/24/2021  17:44           143,666 hf-4tf.ipynb\n",
      "02/24/2021  18:03           105,109 hf-4torch.ipynb\n",
      "02/28/2021  18:43            22,018 hf-bert-2.ipynb\n",
      "02/28/2021  16:34            11,857 hf-gpt2-1 - Copy.ipynb\n",
      "02/28/2021  17:12            13,365 hf-gpt2-2 - Copy.ipynb\n",
      "04/23/2023  20:37               844 how-much-can-gpt-3-remember-in-a-prompt.f8.md\n",
      "05/31/2023  16:59                54 import6.py\n",
      "02/05/2021  14:56            69,239 Installing Intelr Distribution for Python_ and Intelr Performance....html\n",
      "05/12/2023  03:58           294,917 Interactive_Neuroscope.ipynb\n",
      "06/01/2023  20:28    <DIR>          INTRO\n",
      "05/24/2023  13:28           341,236 ipynb based malware reddit - Google Search.html\n",
      "05/21/2023  05:44            29,320 jacobians_hessians.ipynb\n",
      "05/30/2023  00:29               353 JUP-NOTE-235.f8.py\n",
      "06/03/2023  21:16             7,394 JUP-NOTE-236.ipynb\n",
      "05/10/2023  17:31             5,434 kaggle.com--intro.e.f8.py\n",
      "05/08/2023  00:26             1,493 kaggle-default.ipynb\n",
      "05/08/2023  00:36           217,749 kaggle-pip-list.ipynb\n",
      "06/04/2023  01:49    <DIR>          Karpathy\n",
      "05/13/2023  08:19            65,200 layer-Neuroscope.ipynb\n",
      "03/10/2021  16:51             1,068 LICENSE\n",
      "04/24/2023  17:16               116 lifelogging.f8.md\n",
      "05/02/2023  01:00    <DIR>          LNK\n",
      "03/23/2021  18:30             4,529 ls-laR.txt.md\n",
      "05/12/2023  03:19           502,516 Main_Demo.ipynb\n",
      "05/17/2023  03:13                89 minitext-1.txt\n",
      "05/17/2023  04:42                95 minitext-ABCDEF.txt\n",
      "06/03/2023  20:06             6,642 mini-toy-lang-models.e.f8.py\n",
      "05/08/2023  00:52    <DIR>          MORE\n",
      "05/17/2023  01:29                85 my011000-012-vocab.txt\n",
      "05/17/2023  01:29               129 my011000-01-vocab.txt\n",
      "05/17/2023  01:28               203 my011000-0-vocab.txt\n",
      "05/17/2023  01:26               211 my011000-vocab.txt\n",
      "05/17/2023  01:27             2,068 my011001-vocab.txt\n",
      "05/17/2023  01:25             2,279 my011-vocab.txt\n",
      "05/17/2023  01:23            14,053 my01-vocab.txt\n",
      "02/27/2021  16:28           231,508 my0-vocab.txt\n",
      "05/17/2023  01:21           216,099 my1-vocab.txt\n",
      "05/12/2022  20:27               767 myenv.ps1\n",
      "03/23/2021  21:43    <DIR>          nl2bash\n",
      "05/10/2022  20:22               785 nlsh-2.prompt\n",
      "05/10/2022  20:22               761 nlsh-davinci-2.prompt\n",
      "06/03/2023  22:23    <DIR>          OLD\n",
      "05/17/2023  04:06               798 old-code-search-net-tokenizer.json\n",
      "04/29/2023  21:08             3,662 openai.e.f8.sh\n",
      "04/27/2023  21:41                87 openai.e.f8.sh~\n",
      "05/06/2023  22:26             4,088 openai.f8.md\n",
      "02/28/2023  13:11             1,068 openai.f8.txt\n",
      "04/26/2023  17:36               687 openai-234.e.f8.sh~\n",
      "05/14/2023  04:32             3,070 openai-234.f8.md\n",
      "06/01/2023  14:31             7,254 pip----30pip310.e.f8.sh.ps1\n",
      "05/22/2023  12:43           243,256 plot_pca_iris.ipynb\n",
      "05/27/2023  17:30            13,260 plt.hist.ipynb\n",
      "02/22/2021  17:39                84 pokus.ps1\n",
      "05/26/2023  17:26    <DIR>          projector.tensorflow.org\n",
      "03/10/2021  16:51                13 README.md\n",
      "06/18/2022  20:58            13,819 replika.txt.md\n",
      "05/22/2023  10:02    <DIR>          runs\n",
      "03/04/2021  20:48             9,866 sbert.net--quickstart.ipynb\n",
      "02/23/2021  15:02            26,602 scipy-describe.ipynb\n",
      "03/23/2021  21:43    <DIR>          staqc\n",
      "04/26/2023  17:27             1,195 tell me a long story about space robots on the planet 1 trying to survive.md\n",
      "02/13/2021  17:10               201 temp.ipy\n",
      "05/27/2022  19:13             9,925 textsynth-playground-20b.txt.md\n",
      "02/23/2021  13:52            25,802 tf-describe.ipynb\n",
      "06/06/2022  19:38         1,604,848 tokeni.js\n",
      "05/17/2023  01:33         1,355,256 tokenizer.json\n",
      "05/22/2023  10:24            16,652 torch.linalg.eig.ipynb\n",
      "05/06/2023  20:10           298,129 TransformerLens101.ipynb\n",
      "06/03/2023  21:20           116,531 Visualizing_gpt2_token_embeddings.ipynb\n",
      "05/17/2023  01:33         1,042,301 vocab.json\n",
      "03/05/2021  16:42            50,120 w2v.ipynb\n",
      "05/22/2023  11:41           104,936 w2v-EDIT-MNovy-1.ipynb\n",
      "             107 File(s)     10,131,570 bytes\n",
      "              17 Dir(s)  32,667,488,256 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71b20103-59d3-4581-a169-43eaa5d8a43e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mll\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'll' is not defined"
     ]
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f890865-163c-4479-bc94-cf5e00b8b846",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmmll\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mmll' is not defined"
     ]
    }
   ],
   "source": [
    "mmll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6474fb09-c496-4ea2-8911-f9f4da238c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/6886493/get-all-object-attributes-in-python\n",
    "\n",
    "def mmll(a):\n",
    "    for x in dir(a):\n",
    "        print(x, type(getattr(a,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c1bdf-8b7d-4f79-895d-7599a6a98feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d211405e-9434-460e-b868-a8f2c0ba49b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_destination <class 'typing.TypeVar'>\n",
      "__annotations__ <class 'dict'>\n",
      "__call__ <class 'method'>\n",
      "__class__ <class 'type'>\n",
      "__delattr__ <class 'method'>\n",
      "__dict__ <class 'dict'>\n",
      "__dir__ <class 'method'>\n",
      "__doc__ <class 'str'>\n",
      "__eq__ <class 'method-wrapper'>\n",
      "__format__ <class 'builtin_function_or_method'>\n",
      "__ge__ <class 'method-wrapper'>\n",
      "__getattr__ <class 'method'>\n",
      "__getattribute__ <class 'method-wrapper'>\n",
      "__gt__ <class 'method-wrapper'>\n",
      "__hash__ <class 'method-wrapper'>\n",
      "__init__ <class 'method'>\n",
      "__init_subclass__ <class 'builtin_function_or_method'>\n",
      "__le__ <class 'method-wrapper'>\n",
      "__lt__ <class 'method-wrapper'>\n",
      "__module__ <class 'str'>\n",
      "__ne__ <class 'method-wrapper'>\n",
      "__new__ <class 'builtin_function_or_method'>\n",
      "__reduce__ <class 'builtin_function_or_method'>\n",
      "__reduce_ex__ <class 'builtin_function_or_method'>\n",
      "__repr__ <class 'method'>\n",
      "__setattr__ <class 'method'>\n",
      "__setstate__ <class 'method'>\n",
      "__sizeof__ <class 'builtin_function_or_method'>\n",
      "__str__ <class 'method-wrapper'>\n",
      "__subclasshook__ <class 'builtin_function_or_method'>\n",
      "__weakref__ <class 'NoneType'>\n",
      "_apply <class 'method'>\n",
      "_auto_class <class 'NoneType'>\n",
      "_backward_compatibility_gradient_checkpointing <class 'method'>\n",
      "_backward_hooks <class 'collections.OrderedDict'>\n",
      "_buffers <class 'collections.OrderedDict'>\n",
      "_call_impl <class 'method'>\n",
      "_convert_head_mask_to_5d <class 'method'>\n",
      "_create_repo <class 'method'>\n",
      "_expand_inputs_for_generation <class 'function'>\n",
      "_extract_past_from_model_output <class 'method'>\n",
      "_forward_hooks <class 'collections.OrderedDict'>\n",
      "_forward_pre_hooks <class 'collections.OrderedDict'>\n",
      "_from_config <class 'method'>\n",
      "_get_backward_hooks <class 'method'>\n",
      "_get_decoder_start_token_id <class 'method'>\n",
      "_get_files_timestamps <class 'method'>\n",
      "_get_logits_processor <class 'method'>\n",
      "_get_logits_warper <class 'method'>\n",
      "_get_name <class 'method'>\n",
      "_get_resized_embeddings <class 'method'>\n",
      "_get_resized_lm_head <class 'method'>\n",
      "_get_stopping_criteria <class 'method'>\n",
      "_hook_rss_memory_post_forward <class 'function'>\n",
      "_hook_rss_memory_pre_forward <class 'function'>\n",
      "_init_weights <class 'method'>\n",
      "_initialize_weights <class 'method'>\n",
      "_is_full_backward_hook <class 'NoneType'>\n",
      "_is_hf_initialized <class 'bool'>\n",
      "_keep_in_fp32_modules <class 'NoneType'>\n",
      "_keys_to_ignore_on_load_missing <class 'list'>\n",
      "_keys_to_ignore_on_load_unexpected <class 'NoneType'>\n",
      "_keys_to_ignore_on_save <class 'NoneType'>\n",
      "_load_from_state_dict <class 'method'>\n",
      "_load_pretrained_model <class 'method'>\n",
      "_load_pretrained_model_low_mem <class 'function'>\n",
      "_load_state_dict_post_hooks <class 'collections.OrderedDict'>\n",
      "_load_state_dict_pre_hooks <class 'collections.OrderedDict'>\n",
      "_maybe_initialize_input_ids_for_generation <class 'method'>\n",
      "_maybe_warn_non_full_backward_hook <class 'method'>\n",
      "_merge_criteria_processor_list <class 'method'>\n",
      "_modules <class 'collections.OrderedDict'>\n",
      "_named_members <class 'method'>\n",
      "_no_split_modules <class 'list'>\n",
      "_non_persistent_buffers_set <class 'set'>\n",
      "_parameters <class 'collections.OrderedDict'>\n",
      "_prepare_attention_mask_for_generation <class 'method'>\n",
      "_prepare_decoder_input_ids_for_generation <class 'method'>\n",
      "_prepare_encoder_decoder_kwargs_for_generation <class 'method'>\n",
      "_prepare_model_inputs <class 'method'>\n",
      "_register_load_state_dict_pre_hook <class 'method'>\n",
      "_register_state_dict_hook <class 'method'>\n",
      "_reorder_cache <class 'function'>\n",
      "_replicate_for_data_parallel <class 'method'>\n",
      "_resize_token_embeddings <class 'method'>\n",
      "_save_to_state_dict <class 'method'>\n",
      "_set_default_torch_dtype <class 'method'>\n",
      "_set_gradient_checkpointing <class 'method'>\n",
      "_slow_forward <class 'method'>\n",
      "_state_dict_hooks <class 'collections.OrderedDict'>\n",
      "_tie_encoder_decoder_weights <class 'function'>\n",
      "_tie_or_clone_weights <class 'method'>\n",
      "_update_model_kwargs_for_generation <class 'method'>\n",
      "_upload_modified_files <class 'method'>\n",
      "_validate_model_class <class 'method'>\n",
      "_validate_model_kwargs <class 'method'>\n",
      "_version <class 'int'>\n",
      "add_memory_hooks <class 'method'>\n",
      "add_module <class 'method'>\n",
      "adjust_logits_during_generation <class 'method'>\n",
      "apply <class 'method'>\n",
      "assisted_decoding <class 'method'>\n",
      "base_model <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
      "base_model_prefix <class 'str'>\n",
      "beam_sample <class 'method'>\n",
      "beam_search <class 'method'>\n",
      "bfloat16 <class 'method'>\n",
      "buffers <class 'method'>\n",
      "can_generate <class 'method'>\n",
      "children <class 'method'>\n",
      "compute_transition_scores <class 'method'>\n",
      "config <class 'transformers.models.gpt2.configuration_gpt2.GPT2Config'>\n",
      "config_class <class 'type'>\n",
      "constrained_beam_search <class 'method'>\n",
      "contrastive_search <class 'method'>\n",
      "cpu <class 'method'>\n",
      "create_extended_attention_mask_for_decoder <class 'function'>\n",
      "cuda <class 'method'>\n",
      "deparallelize <class 'method'>\n",
      "device <class 'torch.device'>\n",
      "device_map <class 'NoneType'>\n",
      "disable_input_require_grads <class 'method'>\n",
      "double <class 'method'>\n",
      "dtype <class 'torch.dtype'>\n",
      "dummy_inputs <class 'dict'>\n",
      "dump_patches <class 'bool'>\n",
      "enable_input_require_grads <class 'method'>\n",
      "estimate_tokens <class 'method'>\n",
      "eval <class 'method'>\n",
      "extra_repr <class 'method'>\n",
      "float <class 'method'>\n",
      "floating_point_ops <class 'method'>\n",
      "forward <class 'method'>\n",
      "framework <class 'str'>\n",
      "from_pretrained <class 'method'>\n",
      "generate <class 'method'>\n",
      "generation_config <class 'transformers.generation.configuration_utils.GenerationConfig'>\n",
      "get_buffer <class 'method'>\n",
      "get_extended_attention_mask <class 'method'>\n",
      "get_extra_state <class 'method'>\n",
      "get_head_mask <class 'method'>\n",
      "get_input_embeddings <class 'method'>\n",
      "get_memory_footprint <class 'method'>\n",
      "get_output_embeddings <class 'method'>\n",
      "get_parameter <class 'method'>\n",
      "get_position_embeddings <class 'method'>\n",
      "get_submodule <class 'method'>\n",
      "gradient_checkpointing_disable <class 'method'>\n",
      "gradient_checkpointing_enable <class 'method'>\n",
      "greedy_search <class 'method'>\n",
      "group_beam_search <class 'method'>\n",
      "half <class 'method'>\n",
      "init_weights <class 'method'>\n",
      "invert_attention_mask <class 'method'>\n",
      "ipu <class 'method'>\n",
      "is_gradient_checkpointing <class 'bool'>\n",
      "is_loaded_in_8bit <class 'bool'>\n",
      "is_parallelizable <class 'bool'>\n",
      "lm_head <class 'torch.nn.modules.linear.Linear'>\n",
      "load_state_dict <class 'method'>\n",
      "load_tf_weights <class 'method'>\n",
      "main_input_name <class 'str'>\n",
      "model_parallel <class 'bool'>\n",
      "modules <class 'method'>\n",
      "name_or_path <class 'str'>\n",
      "named_buffers <class 'method'>\n",
      "named_children <class 'method'>\n",
      "named_modules <class 'method'>\n",
      "named_parameters <class 'method'>\n",
      "num_parameters <class 'method'>\n",
      "parallelize <class 'method'>\n",
      "parameters <class 'method'>\n",
      "post_init <class 'method'>\n",
      "prepare_inputs_for_generation <class 'method'>\n",
      "prune_heads <class 'method'>\n",
      "push_to_hub <class 'method'>\n",
      "register_backward_hook <class 'method'>\n",
      "register_buffer <class 'method'>\n",
      "register_for_auto_class <class 'method'>\n",
      "register_forward_hook <class 'method'>\n",
      "register_forward_pre_hook <class 'method'>\n",
      "register_full_backward_hook <class 'method'>\n",
      "register_load_state_dict_post_hook <class 'method'>\n",
      "register_module <class 'method'>\n",
      "register_parameter <class 'method'>\n",
      "requires_grad_ <class 'method'>\n",
      "reset_memory_hooks_state <class 'method'>\n",
      "resize_position_embeddings <class 'method'>\n",
      "resize_token_embeddings <class 'method'>\n",
      "retrieve_modules_from_names <class 'method'>\n",
      "reverse_bettertransformer <class 'method'>\n",
      "sample <class 'method'>\n",
      "save_pretrained <class 'method'>\n",
      "set_extra_state <class 'method'>\n",
      "set_input_embeddings <class 'method'>\n",
      "set_output_embeddings <class 'method'>\n",
      "share_memory <class 'method'>\n",
      "state_dict <class 'method'>\n",
      "supports_gradient_checkpointing <class 'bool'>\n",
      "tie_weights <class 'method'>\n",
      "to <class 'method'>\n",
      "to_bettertransformer <class 'method'>\n",
      "to_empty <class 'method'>\n",
      "train <class 'method'>\n",
      "training <class 'bool'>\n",
      "transformer <class 'transformers.models.gpt2.modeling_gpt2.GPT2Model'>\n",
      "type <class 'method'>\n",
      "warnings_issued <class 'dict'>\n",
      "xpu <class 'method'>\n",
      "zero_grad <class 'method'>\n"
     ]
    }
   ],
   "source": [
    "mmll(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c05f6-bbef-43cf-b30b-55af1d0cf8c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d3607a0-9ab3-47d4-a3d4-cf3eee757c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__annotations__ <class 'dict'>\n",
      "__class__ <class 'type'>\n",
      "__class_getitem__ <class 'builtin_function_or_method'>\n",
      "__contains__ <class 'builtin_function_or_method'>\n",
      "__dataclass_fields__ <class 'dict'>\n",
      "__dataclass_params__ <class 'dataclasses._DataclassParams'>\n",
      "__delattr__ <class 'method-wrapper'>\n",
      "__delitem__ <class 'method'>\n",
      "__dict__ <class 'dict'>\n",
      "__dir__ <class 'builtin_function_or_method'>\n",
      "__doc__ <class 'str'>\n",
      "__eq__ <class 'method'>\n",
      "__format__ <class 'builtin_function_or_method'>\n",
      "__ge__ <class 'method-wrapper'>\n",
      "__getattribute__ <class 'method-wrapper'>\n",
      "__getitem__ <class 'method'>\n",
      "__gt__ <class 'method-wrapper'>\n",
      "__hash__ <class 'NoneType'>\n",
      "__init__ <class 'method'>\n",
      "__init_subclass__ <class 'builtin_function_or_method'>\n",
      "__ior__ <class 'method-wrapper'>\n",
      "__iter__ <class 'method-wrapper'>\n",
      "__le__ <class 'method-wrapper'>\n",
      "__len__ <class 'method-wrapper'>\n",
      "__lt__ <class 'method-wrapper'>\n",
      "__match_args__ <class 'tuple'>\n",
      "__module__ <class 'str'>\n",
      "__ne__ <class 'method-wrapper'>\n",
      "__new__ <class 'builtin_function_or_method'>\n",
      "__or__ <class 'method-wrapper'>\n",
      "__post_init__ <class 'method'>\n",
      "__reduce__ <class 'builtin_function_or_method'>\n",
      "__reduce_ex__ <class 'builtin_function_or_method'>\n",
      "__repr__ <class 'method'>\n",
      "__reversed__ <class 'builtin_function_or_method'>\n",
      "__ror__ <class 'method-wrapper'>\n",
      "__setattr__ <class 'method'>\n",
      "__setitem__ <class 'method'>\n",
      "__sizeof__ <class 'builtin_function_or_method'>\n",
      "__str__ <class 'method-wrapper'>\n",
      "__subclasshook__ <class 'builtin_function_or_method'>\n",
      "attentions <class 'NoneType'>\n",
      "clear <class 'builtin_function_or_method'>\n",
      "copy <class 'builtin_function_or_method'>\n",
      "cross_attentions <class 'NoneType'>\n",
      "fromkeys <class 'builtin_function_or_method'>\n",
      "get <class 'builtin_function_or_method'>\n",
      "hidden_states <class 'NoneType'>\n",
      "items <class 'builtin_function_or_method'>\n",
      "keys <class 'builtin_function_or_method'>\n",
      "logits <class 'torch.Tensor'>\n",
      "loss <class 'NoneType'>\n",
      "move_to_end <class 'builtin_function_or_method'>\n",
      "past_key_values <class 'tuple'>\n",
      "pop <class 'method'>\n",
      "popitem <class 'builtin_function_or_method'>\n",
      "setdefault <class 'method'>\n",
      "to_tuple <class 'method'>\n",
      "update <class 'method'>\n",
      "values <class 'builtin_function_or_method'>\n"
     ]
    }
   ],
   "source": [
    "mmll(output_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cca1f4-7af5-4e97-8fc7-00d492ba714d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)\n",
    "type(tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99ebbe-fbf4-43aa-b9a3-f31b56458ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e6e22-1e19-43c8-a890-41ad586e83ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b2974-d857-420c-9967-ed7248c58226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb21a41-4a3a-4246-9817-3bfd8fd84c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1438518-555e-4dc7-be47-d21839bf1b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c0453-5c9e-45d6-9c19-580eed5dc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what mistake is in the re.sub\n",
    "\n",
    "#gpt3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
