{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Notebook for visualizing word embeddings. \n",
    "#\n",
    "# Uses t-SNE from sklearn.manifold followed by adjustText (https://github.com/Phlya/adjustText).\n",
    "#\n",
    "# For the similarity metric for t-SNE, I used cosine similarity since it tends to produce \n",
    "# better visualizations than Euclidean.\n",
    "#\n",
    "# The code below runs t-SNE on the GloVe (https://nlp.stanford.edu/projects/glove/) \n",
    "# embeddings for the most frequent 25K words, plots the top 3K words*, then uses \n",
    "# adjustText to spread out the text labels so they are more readable.\n",
    "# \n",
    "# The files containing the embeddings (glove.840B.300d.top25k.txt) and vocabulary \n",
    "# (vocab.filt.top3k.txt) are provided with this download.\n",
    "# \n",
    "# *Some manual filtering was done to the vocabulary to remove some NSFW word types.\n",
    "#\n",
    "# Kevin Gimpel\n",
    "# 2019-2020\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "random.seed()\n",
    "\n",
    "def loadQueryWordsAsSet(filename):\n",
    "    print(\"Loading query words (as a set) from file\", filename)\n",
    "    f = open(filename,'r')\n",
    "    queryWords = set()\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        queryWords.add(word)\n",
    "    print(\"Done. \",len(queryWords),\" query words loaded!\")\n",
    "    return queryWords\n",
    "\n",
    "def loadEmbeddings(filename):\n",
    "    print(\"Loading embeddings from file\", filename)\n",
    "    f = open(filename,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be generating big figures which helps in distinguishing nearby words.\n",
    "plt.rcParams['figure.figsize'] = [100, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the top 25K most common words in the GloVe embeddings.\n",
    "gembs = loadEmbeddings(\"glove.840B.300d.top25k.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the words in the order in which they are specified in the embeddings dictionary.\n",
    "words = np.array(list(gembs.keys()))\n",
    "# Create the matrix of vectors for running t-SNE by including row vectors for each embedding.\n",
    "gX = np.array([gembs[word] for word in words])\n",
    "# shape should be (25000, 300)\n",
    "gX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t-SNE on the embeddings using cosine similarity as the similarity metric and with at most 2000 iterations\n",
    "mytsne = TSNE(n_components=2,early_exaggeration=12,verbose=2,metric='cosine',init='pca',n_iter=2000)\n",
    "gX_tsne = mytsne.fit_transform(gX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the words to plot. We only use 3000 so that we can more easily distinguish the words \n",
    "# visually, but note that we used many more embeddings when running t-SNE above, which helps \n",
    "# us learn a better projection. \n",
    "wordsToPlot = loadQueryWordsAsSet(\"vocab.filt.top3k.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "alltexts = list()\n",
    "# Go through all positions and words in words array.\n",
    "for i, word in enumerate(words):\n",
    "    # Only plot if the current word is a word we want to plot.\n",
    "    if (word in wordsToPlot):\n",
    "        # Place an invisible point.\n",
    "        plt.scatter(gX_tsne[i,0], gX_tsne[i,1], s=0)\n",
    "        # Create a text element at that point.\n",
    "        currtext = plt.text(gX_tsne[i,0], gX_tsne[i,1], word, family='sans-serif')\n",
    "        # Store the text element.\n",
    "        alltexts.append(currtext)\n",
    "    \n",
    "# Save a pdf of the visualization before we run adjustText.\n",
    "plt.savefig('wordembviz-glove-tsne25k-plot3k-noadj.pdf', format='pdf')\n",
    "# Run adjust_text on the text elements (note: this may take a very long time).\n",
    "print('now running adjust_text...')\n",
    "# Note: using autoalign=True tends to give better results in my experience, but takes much longer.\n",
    "#numiters = adjust_text(alltexts, autoalign=True, lim=200)\n",
    "#numiters = adjust_text(alltexts, autoalign=True, lim=20, save_steps=True, add_step_numbers=False, save_prefix='wordembviz-glove-tsne25k-plot3k-autoalign-step', save_format='pdf')\n",
    "#numiters = adjust_text(alltexts, autoalign=False, lim=20, save_steps=True, add_step_numbers=False, save_prefix='wordembviz-glove-tsne25k-plot3k-step', save_format='pdf')\n",
    "numiters = adjust_text(alltexts, autoalign=False, lim=200)\n",
    "print('done adjust_text, num iterations: ', numiters)\n",
    "plt.savefig('wordembviz-glove-tsne25k-plot3k-adj.pdf', format='pdf')\n",
    "\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
