{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dense-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212be61d-8c61-4ff6-96bf-8d12ca6ea4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d7267-4072-449a-8c50-d753359dc845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\Users\\marti\\.cache\\torch\\sentence_transformers\\sentence-transformers_bert-base-nli-mean-tokens\\sentence_bert_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d697a3-71ff-4ea3-8976-750584d60f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce6ce4-c806-4f7c-82e2-a804e26b1478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-blackjack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2a5251766f4a6ba97a0e43aa03738b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)821d1/.gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1fdb246b3649b895b5197cda19619c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cb9fccd1c44af391a4947b49239276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8d01e821d1/README.md:   0%|          | 0.00/3.95k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5994401608b7416b8daf47037f36a4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d1/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61ce8d3d6344ffaaa1bd0ba9f869ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)01e821d1/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de999327008e4da9a0e9b8c422632c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfa21dcd35e4165add5f1a644bc08d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e044cb78bbe8414db7d274d88f85dbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bb88fec6fa4a7f915bad85fc58b8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c758db89a0014452887c6d1f1e074ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)821d1/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9c40bcbf3d49779987683f3a4f5ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c8adf4b6a0470ba3c28af15689bb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8d01e821d1/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cfe152d9cf49078e54b2f039124d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1e821d1/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#**⚠️ This model is deprecated. Please don't use it as it produces sentence embeddings of low quality. You can find recommended sentence embedding models here: [SBERT.net - Pretrained Models](https://www.sbert.net/docs/pretrained_models.html)**\n",
    "# sentence-transformers/bert-base-nli-mean-tokens\n",
    "\n",
    "\n",
    "#model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "#model=SentenceTransformer('roberta-base-nli-stsb-mean-tokens')\n",
    "#model=SentenceTransformer('bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loose-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "light-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acute-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['king',\n",
    "          'queen',\n",
    "          'man',\n",
    "          'woman',\n",
    "          \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fancy-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['A king.',\n",
    "          'A queen.',\n",
    "          'A man.',\n",
    "          'A woman.',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "personal-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I see a king.',\n",
    "          'I see a queen.',\n",
    "          'I see a man.',\n",
    "          'I see a woman.',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accredited-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Anaconda',\n",
    "             'Python',\n",
    "          'software',\n",
    "                    'snake',\n",
    "       \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "given-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I see a king.',\n",
    "          'I see a queen.',\n",
    "          'I see a royal man.',\n",
    "          'I see a royal woman.',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sorted-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Anaconda is software.',\n",
    "             'Python is software.',\n",
    "          'Python is a snake.',\n",
    "                    'Anaconda is a snake.',\n",
    "       \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-divorce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-hazard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "checked-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentences are encoded by calling model.encode()\n",
    "##sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "sentence_embeddings = model.encode(sentences, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-spring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "positive-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "manual-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "king=embeddings[0]\n",
    "queen=embeddings[1]\n",
    "man=embeddings[2]\n",
    "woman=embeddings[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "thousand-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "###y=king+man-woman\n",
    "y=king+woman-man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "respected-rhythm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6200]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.pytorch_cos_sim(y, queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "organic-vaccine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Anaconda is software. (768,)\n",
      "Sentence: Python is software. (768,)\n",
      "Sentence: Python is a snake. (768,)\n",
      "Sentence: Anaconda is a snake. (768,)\n"
     ]
    }
   ],
   "source": [
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    print(\"Sentence:\", sentence,embedding.shape)\n",
    "    #print(\"Embedding:\", embedding.shape)\n",
    "    #print(\"\")\n",
    "    pass\n",
    "#sentence_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "surrounded-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.pytorch_cos_sim(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "spoken-advice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7914, 0.3255, 0.3684],\n",
       "        [0.7914, 1.0000, 0.5385, 0.4501],\n",
       "        [0.3255, 0.5385, 1.0000, 0.9196],\n",
       "        [0.3684, 0.4501, 0.9196, 1.0000]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-briefing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cheap-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nearby-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "funded-machinery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "man \t woman \t 0.5558\n",
      "king \t man \t 0.4238\n",
      "queen \t woman \t 0.4187\n",
      "king \t woman \t 0.4051\n",
      "queen \t man \t 0.3581\n",
      "king \t queen \t 0.3039\n"
     ]
    }
   ],
   "source": [
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations: #[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "specified-mainland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This framework generates embeddings for each input sentence\n",
      "Embedding: (768,)\n",
      "\n",
      "Sentence: Sentences are passed as a list of string.\n",
      "Embedding: (768,)\n",
      "\n",
      "Sentence: The quick brown fox jumps over the lazy dog.\n",
      "Embedding: (768,)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-screening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-brighton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
